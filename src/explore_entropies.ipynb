{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mat = scipy.io.loadmat(Path(PATH_DATA_MAT, '1.mat'))\n",
    "keys = [key for key in mat.keys() if not key.startswith('__')]\n",
    "\n",
    "[print(key, \"with shape\",mat[key].shape) for key in keys]\n",
    "\n",
    "is_normal_state_mask = pd.Series(mat[\"Class_label\"].squeeze() == 0)\n",
    "keys_entropy = [\"FE\", \"SE\", \"AE\", \"PE\"]\n",
    "\n",
    "print(is_normal_state_mask)\n",
    "\n",
    "entropies: Dict[str,pd.DataFrame]={}\n",
    "for key in keys_entropy:\n",
    "    entropies[key] = pd.DataFrame(mat[key])\n",
    "    print(key, \"\\n\",entropies[key].describe()) \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "standard_scaler=preprocessing.StandardScaler().fit_transform\n",
    "standard_scaler_1d= lambda x: standard_scaler(x.reshape(-1, 1)).reshape(1,-1).squeeze()\n",
    "\n",
    "\n",
    "min_max_scaler=preprocessing.MinMaxScaler().fit_transform\n",
    "min_max_scaler_1d= lambda x: min_max_scaler(x.reshape(-1, 1)).reshape(1,-1).squeeze()\n",
    "\n",
    "\n",
    "def dict_apply_procedture(old_dict: Dict[str, T], procedure) -> Dict[str, T]:\n",
    "    return {k: procedure(v) for k, v in old_dict.items()}\n",
    "    \n",
    "def min_max_dataframe(df: pd.DataFrame):\n",
    "    return pd.DataFrame(min_max_scaler(df))\n",
    "\n",
    "def standard_scale_dataframe(df: pd.DataFrame):\n",
    "    return pd.DataFrame(standard_scaler(df))\n",
    "\n",
    "# fig = plt.figure(figsize=(20,20), tight_layout={\"h_pad\": 2})\n",
    "\n",
    "# ax = fig.add_subplot(3,1, 1)\n",
    "# for name, entropy in entropies.items():\n",
    "#     ax.set_title(\"Original\")\n",
    "#     ax.scatter(entropy.index.tolist(), entropy.loc[:,1],  label=name)\n",
    "#     ax.legend()\n",
    "\n",
    "entropies_scaled = dict_apply_procedture(entropies, min_max_dataframe)\n",
    "# ax = fig.add_subplot(3,1, 2)\n",
    "# for name, entropy in entropies_scaled.items():\n",
    "#     ax.set_title(\"Min_max\")\n",
    "#     ax.scatter(entropy.index.tolist(), entropy.loc[:,1],  label=name)\n",
    "#     ax.legend()\n",
    "    \n",
    "entropies_scaled_2 = dict_apply_procedture(entropies, standard_scale_dataframe)\n",
    "# ax = fig.add_subplot(3,1, 3)\n",
    "# for name, entropy in entropies_scaled_2.items():\n",
    "#     ax.set_title(\"Standard scaler\")\n",
    "#     ax.scatter(entropy.index.tolist(), entropy.loc[:,1],  label=name)\n",
    "#     ax.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null and NaN are the same in Pandas :)\n",
    "\n",
    "def isnull_any(df):\n",
    "    return df.isnull().any()\n",
    "\n",
    "def isnull_values_sum(df):\n",
    "    return df.isnull().values.sum() > 0\n",
    "\n",
    "def isnull_sum(df):\n",
    "    return df.isnull().sum() > 0\n",
    "\n",
    "def isnull_values_any(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "def rows_with_null(df):\n",
    "    return df[df.isnull().any(axis=1)]\n",
    "\n",
    "for name, entropy in entropies_scaled.items():\n",
    "    if (isnull_values_any(entropy)):\n",
    "        print(\"Entropy\", name, \"has null values\")\n",
    "    if (isnull_values_any(entropy)):\n",
    "        print(\"Entropy\", name, \"has null values\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
