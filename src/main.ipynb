{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitanja/odgovori \n",
    "\n",
    "Vrsta istraživanja prema:\n",
    "\n",
    "- svrsi: primijenjena istraživanja\n",
    "\t- zbog toga što se oslanjamo na teoriju radi stvaranja pratkičnog znanstvenog rada\n",
    "\t- U znanstevnom radu su korištene unaprijed poznate teorija o obradi signala, entropijama, čišćenju podataka, optimizaciji parametera i treniranja modela za predikciju. Konkretno, sudionici koji su vozili unutar simulacije su nosili kapicu sa elektrodama koja prikuplja EEG podatke za vrijeme vožnje. Iz prikupljenih podataka, zajedno sa tehnikama obrade podataka i strojnog učenja, proizašao je model koji može predviđati stanje vozača za vrijeme vožnje.\n",
    "- izvoru informacija: Primarno istraživanje\n",
    "\t- u ovom znanstevnom radu podaci su prikupljeni iz prve ruke na način da je promatrano 12 ispitanika u kontroliranim uvjetima. Za svakog ispitanika prikupljena su dva EEG signala\n",
    "- vremenu provedbe: longitudinalno istraživanje\n",
    "\t- bitno je napomenuti da iako je istraživanje longitudinalno ono nema klasične karakteristike longitudinalnog istraživanja u smislu da traje više godina\n",
    "\t- longitudinalno je zbog toga što postoji više točaka u vremenu kad se provodi mjerenje stanja svakog ispitanika. Prvo su prikupljeni podaci za \"normalno\" stanje vožnje a zatim stanje \"umora\". Uzorak podataka za oba stanja vožnje je isti, tj. mjerenje je provedeno na istim ispitanicima za oba stanja\n",
    "\t- ne postoji problem sa nedostajućim podacima zbog malog vremenskog intervala između dva promatranja. Iz perspektive ispitanika mjeranja su vrlo vjerojatno obavljena u jednom danu i nije se dogodilo da je jedan sudionik odustao/nije bio prustan na nekom od dva mjerenja, što je često slučaj sa istraživanjima koja se protežu na više godina i puno sudionika  \n",
    "- načinu prikupljanja: Laboratorijsko istraživanje\n",
    "\t- \"u kontroliranom okruženju kako bi se znanstvenim metodama izolirala ovisna varijabla i uspostavio njezin odnos s drugim varijablama\"\n",
    "\t- Kontrolirano okruženje u kontekstu ovog istraživačkog rada provedeno je u prostoru koji se sadrži kapicu s elektrodama, uređaj za vožnju i software za simulaciju. Podaci su za svakog sudionika prikupljani u sličnim vremenskim intervalima a za stanje \"umora\" su postavljene određena ograničenja koja prekidaju prikupljanje podataka \n",
    "- vrsti korištenja podataka: Kvantitativno istraživanje\n",
    "\t- znanstveni rad prikuplja kvantitativne podatake (EEG signali vozača) i koristi računalne alate (kapica sa elektrodama i software za simulaciju vožnje) za mjenje\n",
    "- stupnju manipulacija varijablama: Eksperimentalno istraživanje\n",
    "\t- istraživanje je provedeno u kontroliranim uvjetima gdje je izmjenjena jedna varijabla prilikom dva mjeranja EEG signala. Ta varijabla je broj minuta koje su vozači morali voziti za vrijeme dva mjeranja.\n",
    "\t\t- U prvom mjerenju vozači su morali voziti 20 minuta, čime je osigurano da voze u normalnom stanju (tj. a *nisu umorni*)\n",
    "\t\t- U drugom mjerenju vozači su morali voziti 40 do 100 minuta čime je osigurano da voze u stanju manjeg fokusa / umornom stanju (tj. da *su umorni*)\n",
    "- dubini: Objašnjavačko istraživanje\n",
    "\t- uspostavljanje uzročno-posljedičnih veza koje omogućuju proširenje generalizacija na slične probleme\n",
    "\t- veza koju istraživanje želi identificirati je veza između vrijednosti entropija elektroda u određenom vremenskom intervalu i varijable stanja vozača u tom istom vremenskom intervalu\n",
    "- vrsti zaključka: deduktivno istrazivanje\n",
    "\t- stvarnost se objašnjava općim zakonima koji upućuju na određene zaključke\n",
    "\n",
    "Podaci sudionika su anonimni u radu se ne spominju ikakve dodatne informacije o sudionicima osim njihovog EEG signala.\n",
    "\n",
    "Jesu li podaci objavljeni prema prvilima istraživačke etike?\n",
    "- Twelve young, healthy men, whose ages ranged from 19–24 years, participated in a highway driving simulator experiment. All participants were recruited from Jiangxi University of Technology and were asked to refrain from any type of medicine and stimuli, such as alcohol or coffee, during the experiment. The participants were able-bodied persons and had normal sleep time. Prior to the experiment, the participants practiced a driving task for 5 minutes to become acquainted with the experimental procedures and purposes. All experimental procedures were performed with a static driving simulator in a controlled lab environment. **This study was approved by the Academic Ethics Committee of Jiangxi University of Technology.**\n",
    "- nitko nije pretrpio štetu kao rezultat sudjelovanja u istraživanju (pretpostavka)\n",
    "- istraživači djeluju u skladu sa zakonom (pretpostavka)\n",
    "- sudoinici su otvoreni i pošteni te se ne upuštaju u prijevaru (pretpostavka)\n",
    "- rezultati nisu namještani (pretpostavka)\n",
    "- sudionici su ostali anonimni\n",
    "- podaci su se tretiraju kao povjerljivi (u podacima nisu nađene dodatne informacije o sudonicima)\n",
    "- sudoinici razumiju prirodu istraživanja (pretpostavka)\n",
    "- sudoinici dobrovoljno pristaju na sudjelovanje (pretpostavka)\n",
    "\n",
    "S obzirom da je istraživački rad odobren od strane etičkog povjerenstva zaključujem da su pretpostavka istinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import scipy.io\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import EntropyHub as eh\n",
    "import argparse\n",
    "import antropy as an\n",
    "from zipfile import ZipFile\n",
    "from typing import TypeVar\n",
    "from typing import Dict, List\n",
    "from typing import Dict\n",
    "from typing import Any, Callable\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, LeavePGroupsOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from postprocess_significant_electrodes_users import caculate_mode_users\n",
    "from postprocess_significant_electrodes_all import caculate_mode_all\n",
    "from pathlib import Path\n",
    "from pandas import Series\n",
    "from pandas import read_pickle, DataFrame\n",
    "from pandas import read_pickle\n",
    "from pandas import DataFrame, set_option, read_pickle\n",
    "from pandas import DataFrame\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas._config.config import set_option\n",
    "from os import getcwd\n",
    "from model import model_svc_wide, wide_params, model_svc, model_mlp\n",
    "from model import model_svc\n",
    "from model import model_rfc, model_mlp, model_svc, model_knn\n",
    "from mne.io import read_raw_cnt\n",
    "from mne import make_fixed_length_epochs\n",
    "from mne.epochs import Epochs\n",
    "from math import gamma\n",
    "from math import floor\n",
    "from joblib import dump, load\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "from itertools import chain, combinations\n",
    "from itertools import accumulate\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "%cd /home/matej/2-fer/uuzop/eeg-driver-fatigue-detection\n",
    "FREQ = 1000\n",
    "num_users = 12\n",
    "EPOCH_SECONDS = 1\n",
    "\n",
    "signal_offset = -20\n",
    "SIGNAL_FILE_DURATION_SECONDS = 600\n",
    "SIGNAL_DURATION_SECONDS_DEFAULT = 300\n",
    "\n",
    "FATIGUE_STR = \"fatigue\"\n",
    "NORMAL_STR = \"normal\"\n",
    "\n",
    "channels_all = [\"HEOL\", \"HEOR\", \"FP1\", \"FP2\", \"VEOU\", \"VEOL\", \"F7\", \"F3\", \"FZ\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"CZ\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPZ\", \"CP4\", \"TP8\", \"A1\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"A2\", \"O1\", \"OZ\", \"O2\", \"FT9\", \"FT10\", \"PO1\", \"PO2\"]\n",
    "\n",
    "channels_good = [\"FP1\", \"FP2\", \"F7\", \"F3\", \"FZ\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"CZ\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPZ\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"OZ\", \"O2\"]\n",
    "\n",
    "channels_bad = list(set(channels_all) - set(channels_good))\n",
    "\n",
    "channels_ignore = []\n",
    "\n",
    "PAPER_G = 2 ** (-5)\n",
    "PAPER_C = 2 ** (-1)\n",
    "PAPER_RFC_TREES = 500\n",
    "PAPER_RFC_INPUT_VARIABLES = 22\n",
    "PAPER_BF_HIDDEN = 22\n",
    "\n",
    "entropy_names = [\"PE\", \"AE\", \"SE\", \"FE\"]\n",
    "\n",
    "states = [NORMAL_STR, FATIGUE_STR]\n",
    "\n",
    "# [PE_FP1, PE_FP2, ... , PE_C3, AE_FP1, AE_FP2, ..., FE_C3]\n",
    "entropy_channel_combinations = [\"{}_{}\".format(entropy, channel) for entropy in entropy_names for channel in channels_good]\n",
    "\n",
    "PATH_CWD = Path(getcwd())\n",
    "PATH_DATA = Path(PATH_CWD, \"data\")\n",
    "PATH_REPORT = Path(PATH_DATA, \"reports\")\n",
    "PATH_DATASET = Path(PATH_DATA, \"dataset\")\n",
    "PATH_MODEL = Path(PATH_DATA, \"models\")\n",
    "\n",
    "PATH_DATAFRAME = Path(PATH_DATA, \"dataframes\")\n",
    "PATH_DATASET_MAT = Path(PATH_DATASET, \"mat\")\n",
    "PATH_DATASET_CNT = Path(PATH_DATASET, \"cnt\")\n",
    "\n",
    "PATH_ZIP_CNT = Path(PATH_DATASET, \"5202739.zip\")\n",
    "PATH_ZIP_MAT = Path(PATH_DATASET, \"5202751.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File saver\n",
    "\n",
    "Custom functions which allow easy persistence of data.\n",
    "\n",
    "In specific cases, it's possible to provide a metadata (Python dictionary) which will be saved as metadata tags on the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FIELD_TAGS = \"user.xdg.tags\"\n",
    "METADATA_FIELD_COMMENT = \"user.xdg.comment\"\n",
    "\n",
    "\n",
    "def load_model(path: Path) -> GridSearchCV:\n",
    "    return pickle.loads(load(path))\n",
    "\n",
    "\n",
    "def load_dataframe(path: Path) -> DataFrame:\n",
    "    return read_pickle(path)\n",
    "\n",
    "\n",
    "def save_to_file(\n",
    "    obj: object,\n",
    "    path: Path,\n",
    "    file_saver: Callable[[object, str], Any] = lambda obj, filename: dump(obj, filename),\n",
    "):\n",
    "    file_saver(obj, str(path))\n",
    "    print(\"Saved file:\\n\", str(path))\n",
    "\n",
    "\n",
    "def save_to_file_with_metadata(\n",
    "    obj: object,\n",
    "    dir: Path,\n",
    "    basename: str,\n",
    "    extension: str,\n",
    "    file_saver: Callable[[object, str], Any] = lambda obj, filename: dump(obj, filename),\n",
    "    metadata: dict = {},\n",
    "):\n",
    "    MAX_FILENAME_LEN = 255\n",
    "    timestamp = datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    metadata_str = dict_to_string(metadata)\n",
    "    metadata_bytes = dict_to_byte_metadata(metadata)\n",
    "    filename = \"-\".join([basename, timestamp, metadata_str + extension]).lower()[:MAX_FILENAME_LEN]\n",
    "    file_path = str(Path(dir, filename))\n",
    "\n",
    "    save_to_file(obj, file_path, file_saver)\n",
    "    os.setxattr(file_path, METADATA_FIELD_TAGS, metadata_bytes)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def save_model(model, model_name, score, directory: Path, metadata={}, name_tag=\"\"):\n",
    "    basename = \"{model_name}-{score:.4f}-{name_tag}\".format(model_name=model_name, score=score, name_tag=name_tag)\n",
    "    file_saver = lambda model, filename: dump(pickle.dumps(model), filename)\n",
    "    return save_to_file_with_metadata(model, directory, basename, \".model\", file_saver, metadata)\n",
    "\n",
    "\n",
    "def save_df_to_disk(df: DataFrame, is_complete_train: bool, dir: Path, name_tag: str, metadata={}):\n",
    "    data_type_str = \"complete\" if is_complete_train else \"partial\"\n",
    "    basename = \"-\".join([data_type_str, name_tag])\n",
    "    metadata = {} if is_complete_train else metadata\n",
    "    file_saver = lambda df, filename: df.to_pickle(str(filename))\n",
    "    return save_to_file_with_metadata(df, dir, basename, \".pkl\", file_saver, metadata=metadata)\n",
    "    \n",
    "\n",
    "\n",
    "def save_npy_to_disk(ndarray: np.ndarray, dir: Path, name_tag: str, metadata: dict = {}):\n",
    "    file_saver = lambda ndarray, filename: np.save(str(filename), ndarray)\n",
    "    return save_to_file_with_metadata(ndarray, dir, name_tag, \".npy\", file_saver, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "### Data scalers\n",
    "1. MinMax scaler\n",
    "2. Standard scaler\n",
    "\n",
    "### Dataframe filtering \n",
    "Checking for null values across:\n",
    "1. Rows\n",
    "2. Columns\n",
    "3. Whole dataset\n",
    "\n",
    "### Glimpse Dataframe\n",
    "Print of the dataframe which shows a sample and basic statistical data for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "\n",
    "def dict_apply_procedture(old_dict: Dict[str, T], procedure) -> Dict[str, T]:\n",
    "    return {k: procedure(v) for k, v in old_dict.items()}\n",
    "\n",
    "\n",
    "def min_max_dataframe(df: DataFrame):\n",
    "    return DataFrame(min_max_scaler(df))\n",
    "\n",
    "\n",
    "def standard_scale_dataframe(df: DataFrame):\n",
    "    return DataFrame(standard_scaler(df))\n",
    "\n",
    "\n",
    "standard_scaler = preprocessing.StandardScaler().fit_transform\n",
    "\n",
    "\n",
    "def standard_scaler_1d(x: np.ndarray) -> np.ndarray:\n",
    "    return standard_scaler(x.reshape(-1, 1)).reshape(1, -1).squeeze()\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler((-1, 1)).fit_transform\n",
    "\n",
    "\n",
    "def min_max_scaler_1d(x):\n",
    "    return min_max_scaler(x.reshape(-1, 1)).reshape(1, -1).squeeze()\n",
    "\n",
    "\n",
    "def isnull_any(df):\n",
    "    # Null and NaN are the same in Pandas :)\n",
    "    return df.isnull().any()\n",
    "\n",
    "\n",
    "def isnull_values_sum(df):\n",
    "    return df.isnull().values.sum() > 0\n",
    "\n",
    "\n",
    "def isnull_sum(df):\n",
    "    return df.isnull().sum() > 0\n",
    "\n",
    "\n",
    "def isnull_values_any(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "\n",
    "def rows_with_null(df):\n",
    "    return df[df.isnull().any(axis=1)]\n",
    "\n",
    "\n",
    "def get_tmin_tmax(start, duration, end_cutoff):\n",
    "    return (start - end_cutoff, start + duration - end_cutoff)\n",
    "\n",
    "\n",
    "def to_numpy_reshape(x):\n",
    "    return DataFrame.to_numpy(x).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def get_cnt_filename(i_user: int, state: str):\n",
    "    return \"{i_user}_{state}.cnt\".format(i_user=i_user, state=state)\n",
    "\n",
    "\n",
    "def glimpse_df(df: DataFrame):\n",
    "\n",
    "    print(\"\\nShowing first 3 data points\\n\")\n",
    "    display(df.head(n=3))\n",
    "\n",
    "    print(\"\\nShowing last 3 data points\\n\")\n",
    "    display(df.tail(n=3))\n",
    "\n",
    "    print(\"\\nShowing 3 radnom data points\\n\")\n",
    "    display(df.sample(n=3))\n",
    "\n",
    "    display(df.describe())\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"[1,2,3] --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(0, len(s) + 1))\n",
    "\n",
    "\n",
    "def get_dictionary_leaves(dictionary: dict):\n",
    "    \"\"\"\n",
    "    {a: 3, b: {c: 3, d: 4}} --> [[a,3], [c,3], [d,4]]\n",
    "    \"\"\"\n",
    "\n",
    "    def get_leaves(pair):\n",
    "        key, value = pair\n",
    "        if type(value) is dict:\n",
    "            return get_dictionary_leaves(value)\n",
    "        return [[key, value]]\n",
    "\n",
    "    result = []\n",
    "    for pair in dictionary.items():\n",
    "        result.extend(get_leaves(pair))\n",
    "    return result\n",
    "\n",
    "\n",
    "def dict_to_byte_metadata(dictionary: dict):\n",
    "    \"\"\"\n",
    "    {a:3, b:2, c:test} ---> \"a 3, b 2, c test\"\n",
    "    \"\"\"\n",
    "    pairs = get_dictionary_leaves(dictionary)\n",
    "    return \",\".join(map(lambda key_value: \" \".join([str(key_value[0]), str(key_value[1])]), pairs)).encode()\n",
    "\n",
    "\n",
    "def dict_to_string(dictionary: dict):\n",
    "    \"\"\"\n",
    "    {accuracy: 73, method: \"net} ---> \"accuracy=73___method=net\"\n",
    "    \"\"\"\n",
    "    pairs = get_dictionary_leaves(dictionary)\n",
    "    return \"__\".join(map(lambda key_value: \"=\".join([str(key_value[0]), str(key_value[1])]), pairs))\n",
    "\n",
    "\n",
    "class Tee(object):\n",
    "    def __init__(self, *files):\n",
    "        self.files = files\n",
    "\n",
    "    def write(self, obj):\n",
    "        for f in self.files:\n",
    "            f.write(obj)\n",
    "            f.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        for f in self.files:\n",
    "            f.flush()\n",
    "\n",
    "\n",
    "def stdout_to_file(file: Path):\n",
    "    f = open(Path(getcwd(), file), \"w\")\n",
    "    sys.stdout = Tee(sys.stdout, f)\n",
    "\n",
    "def print_report(file:Path):\n",
    "    for line in open(file, \"r\").readlines():\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropies\n",
    "\n",
    "- PE - special entropy - calculated by applying the Shannon function to the normalized power spectrum based on the peaks of a Fourier transform\n",
    "- AE - Approximate entropy - calculated in time domain without phase-space reconstruction of signal (short-length time series data)\n",
    "- SE - Sample entropy - similar to AE. Se is less sensitive to changes in data length with larger values corresponding to greater complexity or irregularity in the data\n",
    "- FE - Fuzzy entropy - stable results for different parameters. Best noise resistance using fuzzy membership function.\n",
    "\n",
    "\n",
    "### Input\n",
    "Input for each entropy function is 1-D array.\n",
    "In this project those 1-D arrays are epoch values for a single user and single electrode.\n",
    "\n",
    "Each entropy function caculates the appropriate entropy for the 1-D array of values. General entropy function is given $f\\colon\\mathbb{R^n}\\to\\mathbb{R}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_entropy(x):\n",
    "    return eh.FuzzEn(x, m=2, r=(np.std(x, ddof=0) * 0.2, 1))[0][-1]\n",
    "\n",
    "\n",
    "def sample_entropy(x):\n",
    "    return an.sample_entropy(x)\n",
    "\n",
    "\n",
    "# don't normalize because you have to normalze across all users and not based on 1 user and 1 sample\n",
    "def spectral_entropy(x, freq: float):\n",
    "    return an.spectral_entropy(x, sf=freq, normalize=False)\n",
    "\n",
    "\n",
    "def approximate_entropy(x):\n",
    "    return an.app_entropy(x, order=2)\n",
    "\n",
    "\n",
    "def pd_fuzzy_entropy(x: Series, standardize_input=False) -> float:\n",
    "    # standardization doesnt affect result!\n",
    "    x_np = x.to_numpy()\n",
    "    if standardize_input:\n",
    "        x_np = standard_scaler_1d(x_np)\n",
    "    return fuzzy_entropy(x_np)\n",
    "\n",
    "\n",
    "def pd_sample_entropy(x: Series, standardize_input=False) -> float:\n",
    "    # standardization doesnt affect result!\n",
    "    x_np = x.to_numpy()\n",
    "    if standardize_input:\n",
    "        x_np = standard_scaler_1d(x_np)\n",
    "    return sample_entropy(x_np)\n",
    "\n",
    "\n",
    "def pd_spectral_entropy(x: Series, freq: float, standardize_input=False) -> float:\n",
    "    # standardization doesnt affect result!\n",
    "    x_np = x.to_numpy()\n",
    "    if standardize_input:\n",
    "        x_np = standard_scaler_1d(x_np)\n",
    "    return spectral_entropy(x_np, freq)\n",
    "\n",
    "\n",
    "def pd_approximate_entropy(x: Series, standardize_input=False) -> float:\n",
    "    x_np = x.to_numpy()\n",
    "    if standardize_input:\n",
    "        x_np = min_max_scaler_1d(x_np)\n",
    "    return approximate_entropy(x_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation\n",
    "\n",
    "## Data loading\n",
    "\n",
    "Data is loaded with  MNE library by calling `read_raw_cnt` function on every file inside of `cnt` directory which contains raw data signals. There are 12 study participants who were driving in two driving states `fatigue` and `normal` (2). This combination results in 24 `cnt` files in total.\n",
    "\n",
    "## Signal processing\n",
    "\n",
    "Before transforming the signal to tabluar data it's necessary to filter and crop the signal.\n",
    "\n",
    "### Signal filtering\n",
    "1. 50 Hz notch filter\n",
    "2. 0.15 to 40 Hz band pass\n",
    "\n",
    "Both filters are used to remove the noise from signasl\n",
    "\n",
    "### Signal cropping\n",
    "\n",
    "The original data contains 10 minutes (600 seconds) of recorded data for each state.\n",
    "\n",
    "5 minutes (`300` seconds) is used to obtain results similar from the paper. Therefore, we have to crop the signal to 300 seconds in length.\n",
    "\n",
    "Picking **last** the 5 minutes is preferable over picking the **first** 5 minutes. This is because participants are fatigued the most and the end of the session. Normal state should be more consistant of the whole 10 minutes.  \n",
    "\n",
    "Instead of picking seconds in the range `[300 - 600]` offset of `-20` seconds is applied resulting in the range `[280, 580]`. Offset is used because last few seconds produce unwated signal results (removal of electrodes from the participants)\n",
    "\n",
    "## Epochs\n",
    "\n",
    "Epoch is a segment of data that contains raw values of the signal. Length of the epoch depends on the frequecy of the signal. For signal with frequecy `1000Hz` an epoch for a single second will contain `1000` data points. Generally length of the epoch: $|ep_i| = s\\cdot f$\n",
    "\n",
    "In this case, epoch is created for each second, so the parameters are $s = 1$ and $f = 1000$\n",
    "\n",
    "After filtering the signal it's transformed to epochs. This step finally produces numerical data from the signal.\n",
    "\n",
    "## Dataframe\n",
    "Converting epochs to dataframe is easy. `to_data_frame` produces Pandas Dataframe. Before continuing, columns generated from the MNE library, `time` and `condition`, are dropped because they aren't needed.\n",
    "\n",
    "\n",
    "### Entropy caculation\n",
    "Instead of using raw signal data to train the models later, multiple entropy fusion method will be used instead.\n",
    "\n",
    "Entropies are caculated for each `epoch` for each `electrode` for each `participant`. For a single epoch (1000 elements) a entropy value (single float) will be returned. \n",
    "\n",
    "While itterating over the dataframe with raw values, user id, epoch number and entropy values are appended in the list and other helpful variables from which a new dataframe will be created.\n",
    "\n",
    "## Data cleaning\n",
    "\n",
    "Once the new dataframe is formed with entropy values it's necessary to clean the data. The following is done:\n",
    "1. replace values inf, -inf, NaN with 0\n",
    "2. replace negative values with 0\n",
    "- negative values don't actually occour but -0.0000 does\n",
    "3. scale the data to the range of `[-1, 1]` using the MinMax scaler\n",
    "- note: invalid values that were set to 0 are now set to -1 \n",
    "\n",
    "## Saving dataframes\n",
    "Multiple versions of the dataframe are saved to the disk so that entropies are caculated only once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkpoint = None\n",
    "is_complete_train = True\n",
    "if is_complete_train:\n",
    "    print(\"Performing complete training\")\n",
    "num_users =  num_users\n",
    "signal_duration = SIGNAL_DURATION_SECONDS_DEFAULT\n",
    "epoch_elems = FREQ\n",
    "\n",
    "train_metadata = {\n",
    "    \"is_complete_train\": is_complete_train,\n",
    "    \"num_users\": num_users,\n",
    "    \"sig_seconds\": signal_duration,\n",
    "    \"epoch_elems\": epoch_elems,\n",
    "}\n",
    "\n",
    "def signal_to_epochs(filename: str):\n",
    "    \"\"\"\n",
    "    Load the signal.\n",
    "    Exclude bad channels.\n",
    "    Crops the filter the signal.\n",
    "    Return epoches.\n",
    "\n",
    "    Notes:\n",
    "    eeg = read_raw_cnt(filename, eog=[\"HEOL\", \"HEOR\", \"VEOU\", \"VEOL\"], preload=True, verbose=False\n",
    "\n",
    "    when comparing with and without eog, it changed data dramatically? this is what allowed me to sync data with S\n",
    "    \"\"\"\n",
    "    print(filename)\n",
    "    eeg = read_raw_cnt(filename, preload=True, verbose=False)\n",
    "    eeg.info[\"bads\"].extend(channels_bad)\n",
    "    eeg.pick_channels(channels_good)\n",
    "\n",
    "    signal_total_duration = floor(len(eeg) / FREQ)\n",
    "    start = signal_total_duration - signal_duration + signal_offset\n",
    "    end = signal_total_duration + signal_offset\n",
    "    eeg_filtered = eeg.crop(tmin=start, tmax=end).notch_filter(50).filter(l_freq=0.15, h_freq=40)\n",
    "\n",
    "    return make_fixed_length_epochs(eeg_filtered, duration=EPOCH_SECONDS, preload=True, verbose=False)\n",
    "\n",
    "\n",
    "def epochs_to_dataframe(epochs: Epochs):\n",
    "    \"\"\"\n",
    "    Returns epochs converted to dataframe.\n",
    "    Useless columns are excluded.\n",
    "    \"\"\"\n",
    "    df: DataFrame = epochs.to_data_frame(scalings=dict(eeg=1))\n",
    "    df = df.drop([\"time\", \"condition\", *channels_ignore], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_df(df: DataFrame, columns_to_scale: list):\n",
    "    \"\"\"\n",
    "    Normalizes dataframe by replacing values and scaling them.\n",
    "    Standard scaler scales for each column independently.\n",
    "    \"\"\"\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[df <= 0] = 0\n",
    "    df = df.fillna(0)\n",
    "    df[columns_to_scale] = min_max_scaler(df[columns_to_scale])\n",
    "    return df\n",
    "\n",
    "\n",
    "if df_checkpoint:\n",
    "    \"\"\"\n",
    "    If checkpoint only action to perform is normalizing since entropies are already caculated\n",
    "    \"\"\"\n",
    "    df = normalize_df(read_pickle(Path(df_checkpoint)), entropy_channel_combinations)\n",
    "    save_df_to_disk(df, train_metadata, PATH_DATAFRAME, \"normalized\")\n",
    "    print(\"Only cleaning of existing df was performed.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "npy_matrix = np.zeros(shape=(len(states), num_users, len(entropy_names), signal_duration, len(channels_good)))\n",
    "rows = []\n",
    "for user_id in range(0, num_users):\n",
    "    for state in states:\n",
    "        print(user_id, state)\n",
    "        file_signal = str(Path(PATH_DATASET_CNT, get_cnt_filename(user_id + 1, state)))\n",
    "        epochs = signal_to_epochs(file_signal)\n",
    "        df = epochs_to_dataframe(epochs)\n",
    "        label = 1 if state == FATIGUE_STR else 0\n",
    "\n",
    "        for epoch_id in range(0, signal_duration):\n",
    "            \"\"\"\n",
    "            Filter dataframe rows that have the current epoch are selected.\n",
    "            Caculate entropy array for all channels. Shape (30,)\n",
    "            Create a simple dictionary and use to return append entropies in a proper.\n",
    "            Order of entropies is defined by list entropy_names.\n",
    "\n",
    "            Append to backup matrix\n",
    "            Append to list that contains the label and properly ordered entropies\n",
    "            e.g. [0, PE_FP1, PE_FP2, ... , PE_C3, AE_FP1, AE_FP2, ..., FE_C3]\n",
    "            \"\"\"\n",
    "\n",
    "            df_dict = {}\n",
    "            df_epoch = df.loc[df[\"epoch\"] == epoch_id].head(epoch_elems)\n",
    "            df_channels = df_epoch[channels_good]\n",
    "\n",
    "            df_spectral_entropy = df_channels.apply(func=lambda x: pd_spectral_entropy(x, freq=FREQ, standardize_input=True), axis=0)\n",
    "            df_approximate_entropy = df_channels.apply(func=lambda x: pd_approximate_entropy(x, standardize_input=True), axis=0)\n",
    "            df_sample_entropy = df_channels.apply(func=lambda x: pd_sample_entropy(x, standardize_input=True), axis=0)\n",
    "            df_fuzzy_entropy = df_channels.apply(func=lambda x: pd_fuzzy_entropy(x, standardize_input=True), axis=0)\n",
    "\n",
    "            df_dict = {\n",
    "                \"PE\": df_spectral_entropy,\n",
    "                \"AE\": df_approximate_entropy,\n",
    "                \"SE\": df_sample_entropy,\n",
    "                \"FE\": df_fuzzy_entropy,\n",
    "            }\n",
    "\n",
    "            for i, e in enumerate(entropy_names):\n",
    "                npy_matrix[label][user_id][i][epoch_id] = np.array(df_dict[entropy_names[i]])\n",
    "\n",
    "            rows.append([label, user_id, epoch_id, *df_dict[entropy_names[0]], *df_dict[entropy_names[1]], *df_dict[entropy_names[2]], *df_dict[entropy_names[3]]])\n",
    "\n",
    "        if is_complete_train:\n",
    "            np.save(str(Path(PATH_DATAFRAME, \".raw_matrix\")), npy_matrix)\n",
    "\n",
    "\"\"\"Create dataframe from rows and columns\"\"\"\n",
    "columns = [\"label\", \"user_id\", \"epoch_id\"] + entropy_channel_combinations\n",
    "df = DataFrame(rows, columns=columns)\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "\"\"\"Complete training - save instantly so no error with naming is possible\"\"\"\n",
    "if is_complete_train:\n",
    "    np.save(str(Path(PATH_DATAFRAME, \".raw_npy.npy\")), npy_matrix)\n",
    "    df.to_pickle(str(Path(PATH_DATAFRAME, \".raw_df.pkl\")))\n",
    "\n",
    "\"\"\"Save to files\"\"\"\n",
    "save_npy_to_disk(npy_matrix, PATH_DATAFRAME, \"npy_matrix\", train_metadata)\n",
    "save_df_to_disk(df, is_complete_train, PATH_DATAFRAME, \"raw-with-userid\", train_metadata)\n",
    "df = normalize_df(df, entropy_channel_combinations)\n",
    "glimpse_df(df)\n",
    "print(save_df_to_disk(df, is_complete_train, PATH_DATAFRAME, \"normalized-with-userid\", train_metadata))\n",
    "df = df.drop([\"user_id\", \"epoch_id\"])\n",
    "print(save_df_to_disk(df, is_complete_train, PATH_DATAFRAME, \"normalized\", train_metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing first 3 data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.209317</td>\n",
       "      <td>0.294891</td>\n",
       "      <td>0.133174</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>-0.116481</td>\n",
       "      <td>0.063046</td>\n",
       "      <td>0.144465</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.082721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817313</td>\n",
       "      <td>-0.946274</td>\n",
       "      <td>-0.807386</td>\n",
       "      <td>-0.077408</td>\n",
       "      <td>-0.812991</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>-0.831627</td>\n",
       "      <td>-0.086549</td>\n",
       "      <td>-0.958774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.268841</td>\n",
       "      <td>-0.213876</td>\n",
       "      <td>-0.058541</td>\n",
       "      <td>-0.352989</td>\n",
       "      <td>-0.290602</td>\n",
       "      <td>-0.354629</td>\n",
       "      <td>-0.337714</td>\n",
       "      <td>-0.366898</td>\n",
       "      <td>-0.339992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991332</td>\n",
       "      <td>-0.997530</td>\n",
       "      <td>-0.895272</td>\n",
       "      <td>-0.140533</td>\n",
       "      <td>-0.898464</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>-0.992012</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>-0.922727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.264437</td>\n",
       "      <td>-0.213709</td>\n",
       "      <td>-0.321779</td>\n",
       "      <td>-0.352851</td>\n",
       "      <td>-0.421904</td>\n",
       "      <td>-0.354492</td>\n",
       "      <td>-0.342027</td>\n",
       "      <td>-0.366763</td>\n",
       "      <td>-0.378028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988322</td>\n",
       "      <td>-0.996644</td>\n",
       "      <td>-0.830196</td>\n",
       "      <td>-0.037422</td>\n",
       "      <td>-0.850739</td>\n",
       "      <td>0.186383</td>\n",
       "      <td>-0.989237</td>\n",
       "      <td>-0.368149</td>\n",
       "      <td>-0.810525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    PE_FP1    PE_FP2     PE_F7     PE_F3     PE_FZ     PE_F4  \\\n",
       "0      0  0.209317  0.294891  0.133174  0.065747 -0.116481  0.063046   \n",
       "1      0 -0.268841 -0.213876 -0.058541 -0.352989 -0.290602 -0.354629   \n",
       "2      0 -0.264437 -0.213709 -0.321779 -0.352851 -0.421904 -0.354492   \n",
       "\n",
       "      PE_F8    PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3     FE_PZ  \\\n",
       "0  0.144465  0.042837  0.082721  ... -0.817313 -0.946274 -0.807386 -0.077408   \n",
       "1 -0.337714 -0.366898 -0.339992  ... -0.991332 -0.997530 -0.895272 -0.140533   \n",
       "2 -0.342027 -0.366763 -0.378028  ... -0.988322 -0.996644 -0.830196 -0.037422   \n",
       "\n",
       "      FE_P4     FE_T6     FE_O1     FE_OZ     FE_O2  user_id  \n",
       "0 -0.812991  0.137097 -0.831627 -0.086549 -0.958774        0  \n",
       "1 -0.898464  0.059291 -0.992012  0.048274 -0.922727        0  \n",
       "2 -0.850739  0.186383 -0.989237 -0.368149 -0.810525        0  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing last 3 data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.223214</td>\n",
       "      <td>-0.213739</td>\n",
       "      <td>-0.186230</td>\n",
       "      <td>-0.352876</td>\n",
       "      <td>-0.117740</td>\n",
       "      <td>0.340319</td>\n",
       "      <td>-0.203473</td>\n",
       "      <td>-0.366787</td>\n",
       "      <td>-0.339246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988319</td>\n",
       "      <td>-0.996643</td>\n",
       "      <td>-0.754175</td>\n",
       "      <td>-0.997432</td>\n",
       "      <td>-0.409622</td>\n",
       "      <td>-0.996912</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.413888</td>\n",
       "      <td>-0.997353</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.284287</td>\n",
       "      <td>-0.213903</td>\n",
       "      <td>-0.147141</td>\n",
       "      <td>-0.353011</td>\n",
       "      <td>-0.020959</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.400705</td>\n",
       "      <td>-0.366919</td>\n",
       "      <td>-0.384937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991331</td>\n",
       "      <td>-0.997530</td>\n",
       "      <td>-0.705023</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>-0.692108</td>\n",
       "      <td>-0.997728</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.386990</td>\n",
       "      <td>-0.998036</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.040386</td>\n",
       "      <td>0.145975</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.056981</td>\n",
       "      <td>0.363188</td>\n",
       "      <td>-0.055777</td>\n",
       "      <td>-0.077092</td>\n",
       "      <td>-0.016836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800899</td>\n",
       "      <td>-0.941440</td>\n",
       "      <td>-0.578164</td>\n",
       "      <td>-0.956236</td>\n",
       "      <td>-0.525546</td>\n",
       "      <td>-0.946134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.126120</td>\n",
       "      <td>-0.954907</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    PE_FP1    PE_FP2     PE_F7     PE_F3     PE_FZ     PE_F4  \\\n",
       "7197      1 -0.223214 -0.213739 -0.186230 -0.352876 -0.117740  0.340319   \n",
       "7198      1 -0.284287 -0.213903 -0.147141 -0.353011 -0.020959 -1.000000   \n",
       "7199      1 -0.040386  0.145975  0.138400 -0.056817 -0.056981  0.363188   \n",
       "\n",
       "         PE_F8    PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3  \\\n",
       "7197 -0.203473 -0.366787 -0.339246  ... -0.988319 -0.996643 -0.754175   \n",
       "7198 -0.400705 -0.366919 -0.384937  ... -0.991331 -0.997530 -0.705023   \n",
       "7199 -0.055777 -0.077092 -0.016836  ... -0.800899 -0.941440 -0.578164   \n",
       "\n",
       "         FE_PZ     FE_P4     FE_T6  FE_O1     FE_OZ     FE_O2  user_id  \n",
       "7197 -0.997432 -0.409622 -0.996912   -1.0 -0.413888 -0.997353       11  \n",
       "7198 -0.998095 -0.692108 -0.997728   -1.0 -0.386990 -0.998036       11  \n",
       "7199 -0.956236 -0.525546 -0.946134   -1.0 -0.126120 -0.954907       11  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing 3 radnom data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0.420559</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.353832</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.304630</td>\n",
       "      <td>0.219510</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.350170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.646262</td>\n",
       "      <td>0.032319</td>\n",
       "      <td>0.662915</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.322787</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>1</td>\n",
       "      <td>0.381775</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.342029</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.473750</td>\n",
       "      <td>-0.351078</td>\n",
       "      <td>0.116480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.233761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.546294</td>\n",
       "      <td>0.211334</td>\n",
       "      <td>0.512577</td>\n",
       "      <td>0.492997</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.204564</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>1</td>\n",
       "      <td>0.268054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.310906</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.339325</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.108820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999691</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>0.077642</td>\n",
       "      <td>-0.999932</td>\n",
       "      <td>0.529269</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999715</td>\n",
       "      <td>0.163090</td>\n",
       "      <td>-0.999930</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    PE_FP1  PE_FP2     PE_F7  PE_F3     PE_FZ     PE_F4     PE_F8  \\\n",
       "868       0  0.420559    -1.0  0.353832   -1.0  0.161652  0.304630  0.219510   \n",
       "4642      1  0.381775    -1.0  0.342029   -1.0  0.473750 -0.351078  0.116480   \n",
       "2985      1  0.268054    -1.0  0.397100   -1.0  0.310906 -1.000000 -0.339325   \n",
       "\n",
       "      PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3     FE_PZ     FE_P4  \\\n",
       "868     -1.0  0.350170  ... -0.999717 -1.000000  0.646262  0.032319  0.662915   \n",
       "4642    -1.0  0.233761  ... -0.999717 -1.000000  0.546294  0.211334  0.512577   \n",
       "2985    -1.0  0.108820  ... -0.999691 -0.999992  0.077642 -0.999932  0.529269   \n",
       "\n",
       "         FE_T6     FE_O1     FE_OZ     FE_O2  user_id  \n",
       "868  -1.000000 -0.999740  0.322787 -0.999936        1  \n",
       "4642  0.492997 -0.999740  0.204564 -0.999936        7  \n",
       "2985 -0.999993 -0.999715  0.163090 -0.999930        4  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>-0.903883</td>\n",
       "      <td>0.098153</td>\n",
       "      <td>-0.724004</td>\n",
       "      <td>-0.022082</td>\n",
       "      <td>-0.690965</td>\n",
       "      <td>-0.025598</td>\n",
       "      <td>-0.729406</td>\n",
       "      <td>-0.097114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970908</td>\n",
       "      <td>-0.918479</td>\n",
       "      <td>0.332845</td>\n",
       "      <td>-0.779727</td>\n",
       "      <td>0.285013</td>\n",
       "      <td>-0.753079</td>\n",
       "      <td>-0.972363</td>\n",
       "      <td>0.046798</td>\n",
       "      <td>-0.976073</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.314508</td>\n",
       "      <td>0.276742</td>\n",
       "      <td>0.368863</td>\n",
       "      <td>0.453024</td>\n",
       "      <td>0.340669</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.310877</td>\n",
       "      <td>0.472049</td>\n",
       "      <td>0.308131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125191</td>\n",
       "      <td>0.296989</td>\n",
       "      <td>0.362547</td>\n",
       "      <td>0.424517</td>\n",
       "      <td>0.371594</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>0.320503</td>\n",
       "      <td>0.152111</td>\n",
       "      <td>3.452292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.167985</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.271564</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.263067</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.309987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.166007</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>-0.132894</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147971</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.160845</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.033686</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>0.372477</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.094102</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.399038</td>\n",
       "      <td>-0.354412</td>\n",
       "      <td>0.265769</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>0.239478</td>\n",
       "      <td>-0.383018</td>\n",
       "      <td>0.158110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>0.595382</td>\n",
       "      <td>-0.900736</td>\n",
       "      <td>0.574105</td>\n",
       "      <td>-0.957479</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       PE_FP1       PE_FP2        PE_F7        PE_F3  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000   \n",
       "mean      0.500000     0.089403    -0.903883     0.098153    -0.724004   \n",
       "std       0.500035     0.314508     0.276742     0.368863     0.453024   \n",
       "min       0.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%       0.000000    -0.088150    -1.000000    -0.167985    -1.000000   \n",
       "50%       0.500000     0.147971    -1.000000     0.160845    -1.000000   \n",
       "75%       1.000000     0.335433    -1.000000     0.399038    -0.354412   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             PE_FZ        PE_F4        PE_F8       PE_FT7       PE_FC3  ...  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000  ...   \n",
       "mean     -0.022082    -0.690965    -0.025598    -0.729406    -0.097114  ...   \n",
       "std       0.340669     0.484015     0.310877     0.472049     0.308131  ...   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n",
       "25%      -0.271564    -1.000000    -0.263067    -1.000000    -0.309987  ...   \n",
       "50%       0.020586    -1.000000     0.033686    -1.000000    -0.055816  ...   \n",
       "75%       0.265769    -0.354550     0.239478    -0.383018     0.158110  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "            FE_TP8        FE_T5        FE_P3        FE_PZ        FE_P4  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000   \n",
       "mean     -0.970908    -0.918479     0.332845    -0.779727     0.285013   \n",
       "std       0.125191     0.296989     0.362547     0.424517     0.371594   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%      -0.999717    -1.000000     0.166007    -0.999938     0.099338   \n",
       "50%      -0.999717    -1.000000     0.438100    -0.999938     0.372477   \n",
       "75%      -0.999717    -0.999828     0.595382    -0.900736     0.574105   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             FE_T6        FE_O1        FE_OZ        FE_O2      user_id  \n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000  \n",
       "mean     -0.753079    -0.972363     0.046798    -0.976073     5.500000  \n",
       "std       0.511292     0.131415     0.320503     0.152111     3.452292  \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000     0.000000  \n",
       "25%      -1.000000    -0.999740    -0.132894    -0.999936     2.750000  \n",
       "50%      -1.000000    -0.999740     0.094102    -0.999936     5.500000  \n",
       "75%      -0.957479    -0.999740     0.271222    -0.999936     8.250000  \n",
       "max       1.000000     1.000000     1.000000     1.000000    11.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe (7200, 122)\n",
      "Dataframe columns Index(['label', 'PE_FP1', 'PE_FP2', 'PE_F7', 'PE_F3', 'PE_FZ', 'PE_F4',\n",
      "       'PE_F8', 'PE_FT7', 'PE_FC3',\n",
      "       ...\n",
      "       'FE_TP8', 'FE_T5', 'FE_P3', 'FE_PZ', 'FE_P4', 'FE_T6', 'FE_O1', 'FE_OZ',\n",
      "       'FE_O2', 'user_id'],\n",
      "      dtype='object', length=122)\n"
     ]
    }
   ],
   "source": [
    "df_file = Path(PATH_DATAFRAME,\"complete-normalized-with_user_id-2021-12-08-16-10-19-.pkl\")\n",
    "df = read_pickle(df_file)\n",
    "glimpse_df(df)\n",
    "\n",
    "print(\"Shape of the dataframe\", df.shape)\n",
    "print(\"Dataframe columns\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Models for training are the following 4:\n",
    "- Random Forest\n",
    "- Backpropagation neural network (Multi-layer Perceptron classifier)\n",
    "- SVM (SVC) - Support Vector Machine\n",
    "- KNN - k-nearest neighbors\n",
    "\n",
    "Each model is defined and wrapped around the `GridSearchCV`. Grid seraching training with multiple different model hyperparameters (e.g. C and gamma for SVM) and finds the set of parameters that produce the highest accuracy over the test dataset -- optimal parameters in the defined set of parameters\n",
    "\n",
    "`PAPER_G` and `PAPER_C` are optimal parameters used in the paper. We include them expliclty to prove if they are really optimal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_params = sorted([*np.logspace(-6, 3, 10), 500])  # from 1e-6 to 1000, mutiplying by ten in between\n",
    "\n",
    "svm_parameters = [{\"gamma\": sorted([1e-3, 1e-4, PAPER_G]), \"C\": sorted([PAPER_C, 100, 500, 1000, 1500])}]\n",
    "svm_parameters_wide = [{\"gamma\": wide_params, \"C\": wide_params}]\n",
    "mlp_parameters = {\"alpha\": [0.00001, 0.0001, 0.001, 0.05], \"learning_rate\": [\"constant\", \"adaptive\"]}\n",
    "rfc_parameters = {\"n_estimators\": [PAPER_RFC_TREES], \"max_features\": [PAPER_RFC_INPUT_VARIABLES, \"auto\"]}\n",
    "knn_parameters = {\"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "model_rfc = GridSearchCV(RandomForestClassifier(), rfc_parameters)\n",
    "model_mlp = GridSearchCV(MLPClassifier(activation=\"logistic\", hidden_layer_sizes=PAPER_BF_HIDDEN, max_iter=500), mlp_parameters)\n",
    "model_svc = GridSearchCV(SVC(kernel=\"rbf\"), svm_parameters)\n",
    "model_svc_wide = GridSearchCV(SVC(kernel=\"rbf\"), svm_parameters_wide)\n",
    "model_knn = GridSearchCV(KNeighborsClassifier(), knn_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal SVM parameters using LOPO (leave-one-participant-out)\n",
    "\n",
    "Before performing the training process on the whole dataset, optimal parameter pair `(C, gamma)` for SVM should be caculated\n",
    "LOO provides an unbiased way to optimize SVM parameters.\n",
    "\n",
    "First product of possible parameters `C` and `gamma` is created with `product(wide_params, wide_params)`. This is an itterator pairs of possible pairs `(C, gamma)`.\n",
    "\n",
    "`wide_params` are values of geometric range from `[1E-6 to 1000]`:\n",
    "- `[1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]` \n",
    "\n",
    "For each pair of parameters `(C, gamma)` is created SVM model with those parameters and trained in the following way:\n",
    "- train the model on 11/12 participant and caculate the prediction accuracy for validation participant (1/12) \n",
    "- repreat for all participant\n",
    "- caculate the average accuracy for pair `(C, gamma)`\n",
    "  \n",
    "Pair `(C, gamma)` with the highest accruacy is the optimal pair.\n",
    "\n",
    "## Results\n",
    "\n",
    "Maximum average accuracy is 0.5. Unfortunately, the problem might be that models trained with EEG data don't generalize well with unseen participants. This might be because EEG data that is very individual. The data between participants doesn't have to coorelate in the same time or state context.\n",
    "\n",
    "**If this assumption is correct**, some pairs of parameters will produce very similar top results simply because the all have a common generalization bottleneck: the lack of higher number of participants, not the range of different the parameters.\n",
    "\n",
    "Key takeaway is that optimal SVM parameters should not be chosen with LOPO method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = Path(PATH_DATAFRAME,\"complete-normalized-with_user_id-2021-12-08-16-10-19-.pkl\")\n",
    "stdout_to_file(Path(PATH_REPORT, \"-\".join([\"svm-parameters\", get_timestamp()]) + \".txt\"))\n",
    "\n",
    "df = read_pickle(df_file)\n",
    "X = df.loc[:, ~df.columns.isin([\"label\"])]\n",
    "y = df.loc[:, df.columns.isin([\"label\", \"user_id\"])]\n",
    "training_columns = X.columns.isin(entropy_channel_combinations)\n",
    "\n",
    "groups = X[\"user_id\"].to_numpy()\n",
    "acc_parameters = []\n",
    "\n",
    "for C, gamma in tqdm(list(product(wide_params, wide_params))):\n",
    "    \"\"\"\n",
    "    Itterating over the grid of parameters C and gamma to find the best combination\n",
    "    \"\"\"\n",
    "    model = SVC(kernel=\"rbf\", C=C, gamma=gamma)\n",
    "    acc_total = 0\n",
    "\n",
    "    for train_index, test_index in LeaveOneGroupOut().split(X, y, groups):\n",
    "        \"\"\"\n",
    "        LeaveOneGroupOut where the \"group\" of rows is actaully a single participant.\n",
    "        Effectivly, we are training on 11 participants and testing our accuracy on 1 participant\n",
    "        \"\"\"\n",
    "        X_train, X_test = X.iloc[train_index, training_columns], X.iloc[test_index, training_columns]\n",
    "        y_train, y_test = y.iloc[train_index][\"label\"], y.iloc[test_index][\"label\"]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "        acc_total += acc\n",
    "    acc_parameters.append([acc_total / num_users, C, gamma])\n",
    "\n",
    "print(\"Acc\\t\\t\\tC\\tgamma\")\n",
    "accs = sorted(acc_parameters, key=lambda x: x[0], reverse=True)\n",
    "for acc in accs:\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Acc\t\t\tC\tgamma\n",
      "[0.5, 1e-06, 10.0]\n",
      "[0.5, 1e-05, 10.0]\n",
      "[0.5, 0.0001, 10.0]\n",
      "[0.5, 0.0001, 100.0]\n",
      "[0.5, 0.001, 10.0]\n",
      "[0.5, 0.001, 100.0]\n",
      "[0.5, 0.01, 10.0]\n",
      "[0.5, 0.01, 100.0]\n",
      "[0.5, 0.1, 10.0]\n",
      "[0.5, 0.1, 100.0]\n",
      "[0.5, 1.0, 10.0]\n",
      "[0.5, 1.0, 100.0]\n",
      "[0.5, 10.0, 100.0]\n",
      "[0.5, 100.0, 100.0]\n",
      "[0.5, 500, 100.0]\n",
      "[0.5, 1000.0, 100.0]\n",
      "[0.4997222222222222, 10.0, 10.0]\n",
      "[0.4997222222222222, 100.0, 10.0]\n",
      "[0.4997222222222222, 500, 10.0]\n",
      "[0.4997222222222222, 1000.0, 10.0]\n",
      "[0.4959722222222222, 1e-06, 1000.0]\n",
      "[0.4959722222222222, 1e-05, 1000.0]\n",
      "[0.49583333333333335, 0.0001, 1000.0]\n",
      "[0.49569444444444444, 0.001, 1000.0]\n",
      "[0.4955555555555555, 0.01, 1000.0]\n",
      "[0.4955555555555555, 0.1, 1000.0]\n",
      "[0.4955555555555555, 1.0, 1000.0]\n",
      "[0.4955555555555555, 10.0, 1000.0]\n",
      "[0.4955555555555555, 100.0, 1000.0]\n",
      "[0.4955555555555555, 500, 1000.0]\n",
      "[0.4955555555555555, 1000.0, 1000.0]\n",
      "[0.4877777777777778, 1.0, 500]\n",
      "[0.4877777777777778, 10.0, 500]\n",
      "[0.4877777777777778, 100.0, 500]\n",
      "[0.4877777777777778, 500, 500]\n",
      "[0.4877777777777778, 1000.0, 500]\n",
      "[0.48527777777777775, 1e-06, 100.0]\n",
      "[0.48527777777777775, 1e-05, 100.0]\n",
      "[0.48374999999999996, 1e-06, 500]\n",
      "[0.48374999999999996, 1e-05, 500]\n",
      "[0.48361111111111105, 0.0001, 500]\n",
      "[0.48361111111111105, 0.001, 500]\n",
      "[0.48347222222222225, 0.01, 500]\n",
      "[0.48347222222222225, 0.1, 500]\n",
      "[0.4818055555555556, 1e-06, 0.0001]\n",
      "[0.4818055555555556, 1e-05, 0.0001]\n",
      "[0.4818055555555556, 0.0001, 0.0001]\n",
      "[0.4818055555555556, 0.001, 0.0001]\n",
      "[0.4818055555555556, 0.01, 0.0001]\n",
      "[0.4818055555555556, 0.1, 0.0001]\n",
      "[0.4816666666666667, 1e-06, 1e-06]\n",
      "[0.4816666666666667, 1e-06, 1e-05]\n",
      "[0.4816666666666667, 1e-05, 1e-06]\n",
      "[0.4816666666666667, 1e-05, 1e-05]\n",
      "[0.4816666666666667, 0.0001, 1e-06]\n",
      "[0.4816666666666667, 0.0001, 1e-05]\n",
      "[0.4816666666666667, 0.001, 1e-06]\n",
      "[0.4816666666666667, 0.001, 1e-05]\n",
      "[0.4816666666666667, 0.01, 1e-06]\n",
      "[0.4816666666666667, 0.01, 1e-05]\n",
      "[0.4816666666666667, 0.1, 1e-06]\n",
      "[0.4816666666666667, 0.1, 1e-05]\n",
      "[0.4816666666666667, 1.0, 1e-06]\n",
      "[0.4816666666666667, 1.0, 1e-05]\n",
      "[0.4816666666666667, 10.0, 1e-06]\n",
      "[0.47944444444444434, 1e-06, 0.001]\n",
      "[0.47944444444444434, 1e-05, 0.001]\n",
      "[0.47944444444444434, 0.0001, 0.001]\n",
      "[0.47944444444444434, 0.001, 0.001]\n",
      "[0.47944444444444434, 0.01, 0.001]\n",
      "[0.47152777777777777, 1e-06, 1.0]\n",
      "[0.47152777777777777, 1e-05, 1.0]\n",
      "[0.47152777777777777, 0.0001, 1.0]\n",
      "[0.47152777777777777, 0.001, 1.0]\n",
      "[0.47152777777777777, 0.01, 1.0]\n",
      "[0.45208333333333334, 0.1, 1.0]\n",
      "[0.44555555555555565, 1e-06, 0.01]\n",
      "[0.44555555555555565, 1e-05, 0.01]\n",
      "[0.44555555555555565, 0.0001, 0.01]\n",
      "[0.44555555555555565, 0.001, 0.01]\n",
      "[0.4395833333333332, 1.0, 1.0]\n",
      "[0.43888888888888894, 10.0, 1.0]\n",
      "[0.43888888888888894, 100.0, 1.0]\n",
      "[0.43888888888888894, 500, 1.0]\n",
      "[0.43888888888888894, 1000.0, 1.0]\n",
      "[0.43333333333333335, 1.0, 0.1]\n",
      "[0.42875, 0.01, 0.01]\n",
      "[0.42444444444444457, 0.1, 0.001]\n",
      "[0.4222222222222223, 100.0, 1e-06]\n",
      "[0.4222222222222222, 1.0, 0.0001]\n",
      "[0.4220833333333334, 10.0, 1e-05]\n",
      "[0.41944444444444434, 100.0, 0.1]\n",
      "[0.41805555555555557, 500, 0.1]\n",
      "[0.41805555555555557, 1000.0, 0.1]\n",
      "[0.41625, 0.1, 0.1]\n",
      "[0.40874999999999995, 10.0, 0.1]\n",
      "[0.40111111111111114, 500, 1e-06]\n",
      "[0.3880555555555556, 1.0, 0.01]\n",
      "[0.38055555555555554, 0.1, 0.01]\n",
      "[0.3795833333333334, 10.0, 0.01]\n",
      "[0.37777777777777777, 1000.0, 1e-06]\n",
      "[0.37763888888888886, 100.0, 1e-05]\n",
      "[0.3773611111111111, 1.0, 0.001]\n",
      "[0.37680555555555556, 10.0, 0.0001]\n",
      "[0.37666666666666665, 1e-06, 0.1]\n",
      "[0.37666666666666665, 1e-05, 0.1]\n",
      "[0.37666666666666665, 0.0001, 0.1]\n",
      "[0.37666666666666665, 0.001, 0.1]\n",
      "[0.3730555555555555, 100.0, 0.01]\n",
      "[0.37180555555555556, 0.01, 0.1]\n",
      "[0.3688888888888888, 1000.0, 0.01]\n",
      "[0.36763888888888885, 500, 0.01]\n",
      "[0.34805555555555556, 100.0, 0.001]\n",
      "[0.3361111111111111, 500, 0.001]\n",
      "[0.3326388888888889, 1000.0, 0.001]\n",
      "[0.33069444444444446, 500, 1e-05]\n",
      "[0.3298611111111111, 1000.0, 1e-05]\n",
      "[0.32972222222222225, 10.0, 0.001]\n",
      "[0.32958333333333334, 500, 0.0001]\n",
      "[0.32916666666666666, 100.0, 0.0001]\n",
      "[0.3284722222222223, 1000.0, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_report(Path(PATH_REPORT, \"svm-parameters-2021-12-08-23-25-17.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best entropy combination\n",
    "\n",
    "Before training the models with the whole dataset, all possible combinations of entropy will be explored to find the combination which produces the highest accuracy on the test dataset. 15 possible entropy combinations are: \n",
    "\n",
    "`[('PE',), ('AE',), ('SE',), ('FE',), ('PE', 'AE'), ('PE', 'SE'), ('PE', 'FE'), ('AE', 'SE'), ('AE', 'FE'), ('SE', 'FE'), ('PE', 'AE', 'SE'), ('PE', 'AE', 'FE'), ('PE', 'SE', 'FE'), ('AE', 'SE', 'FE'), ('PE', 'AE', 'SE', 'FE')]` \n",
    "\n",
    "The best combination of entropy features will be used to train 4 already defined models. This step will also show how much each entropy might contribute to importance of predicting participant's driving state.\n",
    "\n",
    "It's assumed that combination with all 4 entropies will produce the highest prediction accuracy on the test dataset simply because model has more data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df_file = Path(PATH_DATAFRAME,\"complete-normalized-with_user_id-2021-12-08-16-10-19-.pkl\")\n",
    "timestamp = get_timestamp()\n",
    "report_ent_filename = Path(PATH_REPORT, \"-\".join([\"best-entropies\", timestamp]) + \".txt\")\n",
    "stdout_to_file(report_ent_filename)\n",
    "\n",
    "\n",
    "df: DataFrame = read_pickle(df_file)\n",
    "X = df.loc[:, ~df.columns.isin([\"label\"])]\n",
    "y = df.loc[:, \"label\"]\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "entropy_excluded_powerset = list(powerset(entropy_names))[:-1]  # Exclude last element where all entropies are mentioned\n",
    "models = [model_svc]\n",
    "scorings = [\"accuracy\"]\n",
    "results = []\n",
    "\n",
    "for i, pair in enumerate(tqdm(list(product(scorings, models, entropy_excluded_powerset)))):\n",
    "    scoring, model, entropies_exclude = pair\n",
    "    (X_train, X_test) = (X_train_org.copy(), X_test_org.copy())\n",
    "\n",
    "    for entropy in entropies_exclude:\n",
    "        X_train = X_train.loc[:, ~X_train.columns.str.startswith(entropy)]\n",
    "        X_test = X_test.loc[:, ~X_test.columns.str.startswith(entropy)]\n",
    "\n",
    "    model.scoring = scoring\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_true_train, y_pred_train = y_train, model.predict(X_train)\n",
    "    y_true_test, y_pred_test = y_test, model.predict(X_test)\n",
    "\n",
    "    classification_report_string = classification_report(y_true_test, y_pred_test, digits=6, output_dict=True)\n",
    "\n",
    "    results.append([i, list(set(entropy_names) - set(entropies_exclude)), model.best_score_, get_dictionary_leaves(classification_report_string)])\n",
    "\n",
    "for result in sorted(results, key=lambda x: x[2], reverse=True):\n",
    "    print(result, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['PE', 'FE', 'SE'] 0.9788888888888888\n",
      "0 ['PE', 'AE', 'FE', 'SE'] 0.9772222222222222\n",
      "1 ['AE', 'FE', 'SE'] 0.9738888888888889\n",
      "3 ['PE', 'AE', 'FE'] 0.9736111111111111\n",
      "8 ['PE', 'FE'] 0.9733333333333334\n",
      "4 ['PE', 'AE', 'SE'] 0.9722222222222221\n",
      "9 ['PE', 'SE'] 0.9719444444444445\n",
      "5 ['FE', 'SE'] 0.971111111111111\n",
      "6 ['AE', 'FE'] 0.971111111111111\n",
      "11 ['FE'] 0.9655555555555555\n",
      "7 ['AE', 'SE'] 0.9625\n",
      "12 ['SE'] 0.9563888888888888\n",
      "10 ['PE', 'AE'] 0.9530555555555555\n",
      "14 ['PE'] 0.9191666666666667\n",
      "13 ['AE'] 0.8577777777777778\n"
     ]
    }
   ],
   "source": [
    "print_report(Path(PATH_REPORT, \"best-entropies-2021-12-10-17-26-22.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Dataframe is loaded and split to `X` and `y` variables. `X` variable contains only 120 features (4 entropies * 30 channels) while `y` variable contains the label of the driving state (`1` - fiatgue, `0` - normal). `train_test_split` `50:50` is used to split the data between train and test dataset. \n",
    "\n",
    "Each model is fitted with the grid search meaning that optimal parameters will be found for the train dataset. Once optimal parameters and accuracy on the test set are found for each model, models and training/validation reports are saved.\n",
    "\n",
    "## Results\n",
    "\n",
    "1. RandomForestClassifier with accuracy 0.98472 and parameters {'max_features': 22, 'n_estimators': 500}\n",
    "2. MLPClassifier with accuracy 0.970278 and parameters {'alpha': 0.0001, 'learning_rate': 'constant'}\n",
    "3. KNeighborsClassifier with accuracy 0.96138 and parameters {'weights': 'distance'}\n",
    "4. SVC with accuracy 0.9772 and parameters {'C': 100, 'gamma': 0.03125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing first 3 data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.209317</td>\n",
       "      <td>0.294891</td>\n",
       "      <td>0.133174</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>-0.116481</td>\n",
       "      <td>0.063046</td>\n",
       "      <td>0.144465</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.082721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817313</td>\n",
       "      <td>-0.946274</td>\n",
       "      <td>-0.807386</td>\n",
       "      <td>-0.077408</td>\n",
       "      <td>-0.812991</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>-0.831627</td>\n",
       "      <td>-0.086549</td>\n",
       "      <td>-0.958774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.268841</td>\n",
       "      <td>-0.213876</td>\n",
       "      <td>-0.058541</td>\n",
       "      <td>-0.352989</td>\n",
       "      <td>-0.290602</td>\n",
       "      <td>-0.354629</td>\n",
       "      <td>-0.337714</td>\n",
       "      <td>-0.366898</td>\n",
       "      <td>-0.339992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991332</td>\n",
       "      <td>-0.997530</td>\n",
       "      <td>-0.895272</td>\n",
       "      <td>-0.140533</td>\n",
       "      <td>-0.898464</td>\n",
       "      <td>0.059291</td>\n",
       "      <td>-0.992012</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>-0.922727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.264437</td>\n",
       "      <td>-0.213709</td>\n",
       "      <td>-0.321779</td>\n",
       "      <td>-0.352851</td>\n",
       "      <td>-0.421904</td>\n",
       "      <td>-0.354492</td>\n",
       "      <td>-0.342027</td>\n",
       "      <td>-0.366763</td>\n",
       "      <td>-0.378028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988322</td>\n",
       "      <td>-0.996644</td>\n",
       "      <td>-0.830196</td>\n",
       "      <td>-0.037422</td>\n",
       "      <td>-0.850739</td>\n",
       "      <td>0.186383</td>\n",
       "      <td>-0.989237</td>\n",
       "      <td>-0.368149</td>\n",
       "      <td>-0.810525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    PE_FP1    PE_FP2     PE_F7     PE_F3     PE_FZ     PE_F4  \\\n",
       "0      0  0.209317  0.294891  0.133174  0.065747 -0.116481  0.063046   \n",
       "1      0 -0.268841 -0.213876 -0.058541 -0.352989 -0.290602 -0.354629   \n",
       "2      0 -0.264437 -0.213709 -0.321779 -0.352851 -0.421904 -0.354492   \n",
       "\n",
       "      PE_F8    PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3     FE_PZ  \\\n",
       "0  0.144465  0.042837  0.082721  ... -0.817313 -0.946274 -0.807386 -0.077408   \n",
       "1 -0.337714 -0.366898 -0.339992  ... -0.991332 -0.997530 -0.895272 -0.140533   \n",
       "2 -0.342027 -0.366763 -0.378028  ... -0.988322 -0.996644 -0.830196 -0.037422   \n",
       "\n",
       "      FE_P4     FE_T6     FE_O1     FE_OZ     FE_O2  user_id  \n",
       "0 -0.812991  0.137097 -0.831627 -0.086549 -0.958774        0  \n",
       "1 -0.898464  0.059291 -0.992012  0.048274 -0.922727        0  \n",
       "2 -0.850739  0.186383 -0.989237 -0.368149 -0.810525        0  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing last 3 data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.223214</td>\n",
       "      <td>-0.213739</td>\n",
       "      <td>-0.186230</td>\n",
       "      <td>-0.352876</td>\n",
       "      <td>-0.117740</td>\n",
       "      <td>0.340319</td>\n",
       "      <td>-0.203473</td>\n",
       "      <td>-0.366787</td>\n",
       "      <td>-0.339246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988319</td>\n",
       "      <td>-0.996643</td>\n",
       "      <td>-0.754175</td>\n",
       "      <td>-0.997432</td>\n",
       "      <td>-0.409622</td>\n",
       "      <td>-0.996912</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.413888</td>\n",
       "      <td>-0.997353</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.284287</td>\n",
       "      <td>-0.213903</td>\n",
       "      <td>-0.147141</td>\n",
       "      <td>-0.353011</td>\n",
       "      <td>-0.020959</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.400705</td>\n",
       "      <td>-0.366919</td>\n",
       "      <td>-0.384937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991331</td>\n",
       "      <td>-0.997530</td>\n",
       "      <td>-0.705023</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>-0.692108</td>\n",
       "      <td>-0.997728</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.386990</td>\n",
       "      <td>-0.998036</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.040386</td>\n",
       "      <td>0.145975</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.056981</td>\n",
       "      <td>0.363188</td>\n",
       "      <td>-0.055777</td>\n",
       "      <td>-0.077092</td>\n",
       "      <td>-0.016836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800899</td>\n",
       "      <td>-0.941440</td>\n",
       "      <td>-0.578164</td>\n",
       "      <td>-0.956236</td>\n",
       "      <td>-0.525546</td>\n",
       "      <td>-0.946134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.126120</td>\n",
       "      <td>-0.954907</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    PE_FP1    PE_FP2     PE_F7     PE_F3     PE_FZ     PE_F4  \\\n",
       "7197      1 -0.223214 -0.213739 -0.186230 -0.352876 -0.117740  0.340319   \n",
       "7198      1 -0.284287 -0.213903 -0.147141 -0.353011 -0.020959 -1.000000   \n",
       "7199      1 -0.040386  0.145975  0.138400 -0.056817 -0.056981  0.363188   \n",
       "\n",
       "         PE_F8    PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3  \\\n",
       "7197 -0.203473 -0.366787 -0.339246  ... -0.988319 -0.996643 -0.754175   \n",
       "7198 -0.400705 -0.366919 -0.384937  ... -0.991331 -0.997530 -0.705023   \n",
       "7199 -0.055777 -0.077092 -0.016836  ... -0.800899 -0.941440 -0.578164   \n",
       "\n",
       "         FE_PZ     FE_P4     FE_T6  FE_O1     FE_OZ     FE_O2  user_id  \n",
       "7197 -0.997432 -0.409622 -0.996912   -1.0 -0.413888 -0.997353       11  \n",
       "7198 -0.998095 -0.692108 -0.997728   -1.0 -0.386990 -0.998036       11  \n",
       "7199 -0.956236 -0.525546 -0.946134   -1.0 -0.126120 -0.954907       11  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing 3 radnom data points\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.184344</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.268709</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.029334</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.155428</td>\n",
       "      <td>-0.318624</td>\n",
       "      <td>0.166951</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-0.997708</td>\n",
       "      <td>0.693088</td>\n",
       "      <td>0.140540</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.405736</td>\n",
       "      <td>-0.99974</td>\n",
       "      <td>-0.113937</td>\n",
       "      <td>-0.988199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>1</td>\n",
       "      <td>0.290713</td>\n",
       "      <td>-0.229381</td>\n",
       "      <td>0.542583</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.401464</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.360373</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979737</td>\n",
       "      <td>-0.999888</td>\n",
       "      <td>0.584358</td>\n",
       "      <td>-0.999719</td>\n",
       "      <td>0.593716</td>\n",
       "      <td>-0.468809</td>\n",
       "      <td>-0.99974</td>\n",
       "      <td>0.499922</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.068762</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.442296</td>\n",
       "      <td>0.51397</td>\n",
       "      <td>-0.553710</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.602066</td>\n",
       "      <td>-0.383615</td>\n",
       "      <td>-0.776535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-0.340068</td>\n",
       "      <td>0.680518</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>0.662486</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.99974</td>\n",
       "      <td>0.403044</td>\n",
       "      <td>-0.991886</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    PE_FP1    PE_FP2     PE_F7    PE_F3     PE_FZ  PE_F4     PE_F8  \\\n",
       "158       0 -0.184344 -1.000000 -0.268709 -1.00000 -0.029334   -1.0 -0.155428   \n",
       "2747      1  0.290713 -0.229381  0.542583 -1.00000  0.401464   -1.0  0.360373   \n",
       "4879      0 -0.068762 -1.000000 -0.442296  0.51397 -0.553710   -1.0 -0.602066   \n",
       "\n",
       "        PE_FT7    PE_FC3  ...    FE_TP8     FE_T5     FE_P3     FE_PZ  \\\n",
       "158  -0.318624  0.166951  ... -0.999717 -0.997708  0.693088  0.140540   \n",
       "2747 -1.000000  0.157470  ... -0.979737 -0.999888  0.584358 -0.999719   \n",
       "4879 -0.383615 -0.776535  ... -0.999717 -0.340068  0.680518  0.028959   \n",
       "\n",
       "         FE_P4     FE_T6    FE_O1     FE_OZ     FE_O2  user_id  \n",
       "158   0.506213  0.405736 -0.99974 -0.113937 -0.988199        0  \n",
       "2747  0.593716 -0.468809 -0.99974  0.499922 -0.999936        4  \n",
       "4879  0.662486 -1.000000 -0.99974  0.403044 -0.991886        8  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PE_FP1</th>\n",
       "      <th>PE_FP2</th>\n",
       "      <th>PE_F7</th>\n",
       "      <th>PE_F3</th>\n",
       "      <th>PE_FZ</th>\n",
       "      <th>PE_F4</th>\n",
       "      <th>PE_F8</th>\n",
       "      <th>PE_FT7</th>\n",
       "      <th>PE_FC3</th>\n",
       "      <th>...</th>\n",
       "      <th>FE_TP8</th>\n",
       "      <th>FE_T5</th>\n",
       "      <th>FE_P3</th>\n",
       "      <th>FE_PZ</th>\n",
       "      <th>FE_P4</th>\n",
       "      <th>FE_T6</th>\n",
       "      <th>FE_O1</th>\n",
       "      <th>FE_OZ</th>\n",
       "      <th>FE_O2</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>-0.903883</td>\n",
       "      <td>0.098153</td>\n",
       "      <td>-0.724004</td>\n",
       "      <td>-0.022082</td>\n",
       "      <td>-0.690965</td>\n",
       "      <td>-0.025598</td>\n",
       "      <td>-0.729406</td>\n",
       "      <td>-0.097114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970908</td>\n",
       "      <td>-0.918479</td>\n",
       "      <td>0.332845</td>\n",
       "      <td>-0.779727</td>\n",
       "      <td>0.285013</td>\n",
       "      <td>-0.753079</td>\n",
       "      <td>-0.972363</td>\n",
       "      <td>0.046798</td>\n",
       "      <td>-0.976073</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.314508</td>\n",
       "      <td>0.276742</td>\n",
       "      <td>0.368863</td>\n",
       "      <td>0.453024</td>\n",
       "      <td>0.340669</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.310877</td>\n",
       "      <td>0.472049</td>\n",
       "      <td>0.308131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125191</td>\n",
       "      <td>0.296989</td>\n",
       "      <td>0.362547</td>\n",
       "      <td>0.424517</td>\n",
       "      <td>0.371594</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>0.320503</td>\n",
       "      <td>0.152111</td>\n",
       "      <td>3.452292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.167985</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.271564</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.263067</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.309987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.166007</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>-0.132894</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147971</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.160845</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.033686</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>0.372477</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.094102</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.399038</td>\n",
       "      <td>-0.354412</td>\n",
       "      <td>0.265769</td>\n",
       "      <td>-0.354550</td>\n",
       "      <td>0.239478</td>\n",
       "      <td>-0.383018</td>\n",
       "      <td>0.158110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999717</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>0.595382</td>\n",
       "      <td>-0.900736</td>\n",
       "      <td>0.574105</td>\n",
       "      <td>-0.957479</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       PE_FP1       PE_FP2        PE_F7        PE_F3  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000   \n",
       "mean      0.500000     0.089403    -0.903883     0.098153    -0.724004   \n",
       "std       0.500035     0.314508     0.276742     0.368863     0.453024   \n",
       "min       0.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%       0.000000    -0.088150    -1.000000    -0.167985    -1.000000   \n",
       "50%       0.500000     0.147971    -1.000000     0.160845    -1.000000   \n",
       "75%       1.000000     0.335433    -1.000000     0.399038    -0.354412   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             PE_FZ        PE_F4        PE_F8       PE_FT7       PE_FC3  ...  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000  ...   \n",
       "mean     -0.022082    -0.690965    -0.025598    -0.729406    -0.097114  ...   \n",
       "std       0.340669     0.484015     0.310877     0.472049     0.308131  ...   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n",
       "25%      -0.271564    -1.000000    -0.263067    -1.000000    -0.309987  ...   \n",
       "50%       0.020586    -1.000000     0.033686    -1.000000    -0.055816  ...   \n",
       "75%       0.265769    -0.354550     0.239478    -0.383018     0.158110  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "            FE_TP8        FE_T5        FE_P3        FE_PZ        FE_P4  \\\n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000   \n",
       "mean     -0.970908    -0.918479     0.332845    -0.779727     0.285013   \n",
       "std       0.125191     0.296989     0.362547     0.424517     0.371594   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%      -0.999717    -1.000000     0.166007    -0.999938     0.099338   \n",
       "50%      -0.999717    -1.000000     0.438100    -0.999938     0.372477   \n",
       "75%      -0.999717    -0.999828     0.595382    -0.900736     0.574105   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             FE_T6        FE_O1        FE_OZ        FE_O2      user_id  \n",
       "count  7200.000000  7200.000000  7200.000000  7200.000000  7200.000000  \n",
       "mean     -0.753079    -0.972363     0.046798    -0.976073     5.500000  \n",
       "std       0.511292     0.131415     0.320503     0.152111     3.452292  \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000     0.000000  \n",
       "25%      -1.000000    -0.999740    -0.132894    -0.999936     2.750000  \n",
       "50%      -1.000000    -0.999740     0.094102    -0.999936     5.500000  \n",
       "75%      -0.957479    -0.999740     0.271222    -0.999936     8.250000  \n",
       "max       1.000000     1.000000     1.000000     1.000000    11.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_file = Path(PATH_DATAFRAME,\"complete-normalized-with_user_id-2021-12-08-16-10-19-.pkl\")\n",
    "report_ent_filename = Path(PATH_REPORT, \"-\".join([\"best-entropies\", get_timestamp()]) + \".txt\")\n",
    "stdout_to_file(report_ent_filename)\n",
    "\n",
    "\n",
    "df = read_pickle(df_file)\n",
    "glimpse_df(df)\n",
    "\n",
    "df = df.loc[:, df.columns.isin([\"label\", *entropy_channel_combinations])]\n",
    "X = df.loc[:, ~df.columns.isin([\"label\"])]\n",
    "y = df.loc[:, \"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "scorings = [\"accuracy\"]  # scorings = [\"accuracy\", \"f1\"]\n",
    "models = [model_rfc, model_mlp, model_knn, model_svc]\n",
    "for pair in product(scorings, models):\n",
    "    scoring, model = pair\n",
    "\n",
    "    model_name = type(model.estimator).__name__\n",
    "    model.scoring = scoring\n",
    "    model.fit(X_train, y_train)\n",
    "    save_model(model=model, model_name=model_name, score=model.best_score_, directory=PATH_MODEL, metadata=model.best_params_)\n",
    "\n",
    "    print(\"=== Best model {} with accuracy {} and parameters {}\\n\\n\".format(model_name, model.best_score_, model.best_params_))\n",
    "    print(\"Grid scores on test set:\\n\")\n",
    "    means = model.cv_results_[\"mean_test_score\"]\n",
    "    stds = model.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in sorted(zip(means, stds, model.cv_results_[\"params\"]), key=lambda x: x[0]):\n",
    "        print(\"%0.6f (+/-%0.6f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "    y_true_train, y_pred_train = y_train, model.predict(X_train)\n",
    "    y_true_test, y_pred_test = y_test, model.predict(X_test)\n",
    "\n",
    "    print(\"\\nReport on train set:\")\n",
    "    classification_report_string = classification_report(y_true_train, y_pred_train, digits=6)\n",
    "    print(classification_report_string)\n",
    "\n",
    "    print(\"Report on test set:\")\n",
    "    classification_report_string = classification_report(y_true_test, y_pred_test, digits=6)\n",
    "    print(classification_report_string)\n",
    "\n",
    "glimpse_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved file:\n",
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection/data/models/randomforestclassifier-0.9847--2021-12-09-19-19-17-max_features=22__n_estimators=500.model\n",
      "\n",
      "=== Best model RandomForestClassifier with accuracy 0.9847222222222222 and parameters {'max_features': 22, 'n_estimators': 500}\n",
      "\n",
      "\n",
      "Grid scores on test set:\n",
      "\n",
      "0.984444 (+/-0.011967) for {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.984722 (+/-0.014487) for {'max_features': 22, 'n_estimators': 500}\n",
      "\n",
      "Report on train set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   1.000000  1.000000  1.000000      1812\n",
      "1   1.000000  1.000000  1.000000      1788\n",
      "\n",
      "accuracy                       1.000000      3600\n",
      "macro avg   1.000000  1.000000  1.000000      3600\n",
      "weighted avg   1.000000  1.000000  1.000000      3600\n",
      "\n",
      "Report on test set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   0.994350  0.984340  0.989320      1788\n",
      "1   0.984699  0.994481  0.989566      1812\n",
      "\n",
      "accuracy                       0.989444      3600\n",
      "macro avg   0.989525  0.989411  0.989443      3600\n",
      "weighted avg   0.989493  0.989444  0.989444      3600\n",
      "\n",
      "Saved file:\n",
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection/data/models/mlpclassifier-0.9703--2021-12-09-19-28-00-alpha=0.0001__learning_rate=constant.model\n",
      "=== Best model MLPClassifier with accuracy 0.9702777777777778 and parameters {'alpha': 0.0001, 'learning_rate': 'constant'}\n",
      "\n",
      "\n",
      "Grid scores on test set:\n",
      "\n",
      "0.963889 (+/-0.020563) for {'alpha': 0.05, 'learning_rate': 'constant'}\n",
      "0.964167 (+/-0.010744) for {'alpha': 0.05, 'learning_rate': 'adaptive'}\n",
      "0.964444 (+/-0.020979) for {'alpha': 0.001, 'learning_rate': 'adaptive'}\n",
      "0.966667 (+/-0.015811) for {'alpha': 0.0001, 'learning_rate': 'adaptive'}\n",
      "0.966944 (+/-0.013540) for {'alpha': 1e-05, 'learning_rate': 'adaptive'}\n",
      "0.967778 (+/-0.021617) for {'alpha': 1e-05, 'learning_rate': 'constant'}\n",
      "0.968333 (+/-0.019116) for {'alpha': 0.001, 'learning_rate': 'constant'}\n",
      "0.970278 (+/-0.016997) for {'alpha': 0.0001, 'learning_rate': 'constant'}\n",
      "\n",
      "Report on train set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   0.994505  0.998896  0.996696      1812\n",
      "1   0.998876  0.994407  0.996637      1788\n",
      "\n",
      "accuracy                       0.996667      3600\n",
      "macro avg   0.996691  0.996652  0.996666      3600\n",
      "weighted avg   0.996676  0.996667  0.996667      3600\n",
      "\n",
      "Report on test set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   0.974818  0.974273  0.974545      1788\n",
      "1   0.974628  0.975166  0.974897      1812\n",
      "\n",
      "accuracy                       0.974722      3600\n",
      "macro avg   0.974723  0.974719  0.974721      3600\n",
      "weighted avg   0.974722  0.974722  0.974722      3600\n",
      "\n",
      "Saved file:\n",
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection/data/models/kneighborsclassifier-0.9614--2021-12-09-19-28-01-weights=distance.model\n",
      "=== Best model KNeighborsClassifier with accuracy 0.9613888888888888 and parameters {'weights': 'distance'}\n",
      "\n",
      "\n",
      "Grid scores on test set:\n",
      "\n",
      "0.958611 (+/-0.016611) for {'weights': 'uniform'}\n",
      "0.961389 (+/-0.017515) for {'weights': 'distance'}\n",
      "\n",
      "Report on train set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   1.000000  1.000000  1.000000      1812\n",
      "1   1.000000  1.000000  1.000000      1788\n",
      "\n",
      "accuracy                       1.000000      3600\n",
      "macro avg   1.000000  1.000000  1.000000      3600\n",
      "weighted avg   1.000000  1.000000  1.000000      3600\n",
      "\n",
      "Report on test set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   0.959430  0.978747  0.968992      1788\n",
      "1   0.978604  0.959161  0.968785      1812\n",
      "\n",
      "accuracy                       0.968889      3600\n",
      "macro avg   0.969017  0.968954  0.968889      3600\n",
      "weighted avg   0.969081  0.968889  0.968888      3600\n",
      "\n",
      "Saved file:\n",
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection/data/models/svc-0.9772--2021-12-09-19-28-39-c=100__gamma=0.03125.model\n",
      "=== Best model SVC with accuracy 0.9772222222222222 and parameters {'C': 100, 'gamma': 0.03125}\n",
      "\n",
      "\n",
      "Grid scores on test set:\n",
      "\n",
      "0.503333 (+/-0.001361) for {'C': 0.5, 'gamma': 0.0001}\n",
      "0.720000 (+/-0.014657) for {'C': 0.5, 'gamma': 0.001}\n",
      "0.819722 (+/-0.018543) for {'C': 100, 'gamma': 0.0001}\n",
      "0.849722 (+/-0.016979) for {'C': 500, 'gamma': 0.0001}\n",
      "0.858333 (+/-0.021517) for {'C': 1000, 'gamma': 0.0001}\n",
      "0.861389 (+/-0.026376) for {'C': 1500, 'gamma': 0.0001}\n",
      "0.904444 (+/-0.030902) for {'C': 100, 'gamma': 0.001}\n",
      "0.940278 (+/-0.025337) for {'C': 0.5, 'gamma': 0.03125}\n",
      "0.943056 (+/-0.019003) for {'C': 500, 'gamma': 0.001}\n",
      "0.956389 (+/-0.015376) for {'C': 1000, 'gamma': 0.001}\n",
      "0.960556 (+/-0.017621) for {'C': 1500, 'gamma': 0.001}\n",
      "0.973611 (+/-0.016005) for {'C': 1000, 'gamma': 0.03125}\n",
      "0.973611 (+/-0.016005) for {'C': 1500, 'gamma': 0.03125}\n",
      "0.973889 (+/-0.016140) for {'C': 500, 'gamma': 0.03125}\n",
      "0.977222 (+/-0.010031) for {'C': 100, 'gamma': 0.03125}\n",
      "\n",
      "Report on train set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   1.000000  1.000000  1.000000      1812\n",
      "1   1.000000  1.000000  1.000000      1788\n",
      "\n",
      "accuracy                       1.000000      3600\n",
      "macro avg   1.000000  1.000000  1.000000      3600\n",
      "weighted avg   1.000000  1.000000  1.000000      3600\n",
      "\n",
      "Report on test set:\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "0   0.980370  0.977629  0.978997      1788\n",
      "1   0.977986  0.980684  0.979333      1812\n",
      "\n",
      "accuracy                       0.979167      3600\n",
      "macro avg   0.979178  0.979156  0.979165      3600\n",
      "weighted avg   0.979170  0.979167  0.979166      3600\n"
     ]
    }
   ],
   "source": [
    "print_report(Path(PATH_REPORT, \"train-models-2021-12-09-19-17-19.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significant electrodes\n",
    "\n",
    "Some electrodes are more important for predicting driver's state. To find the most significant electrodes we will use methods described in paper where we caculate weights for each electrode. Electrode with the highest weight is considered to be the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 - caculate significant electrodes for each user\n",
    "In this method weights for each electrode is caculated for each user. Once all weights are obtained, average weights across all users and all electrodes is caculated, resulting in 30 average weights for each electrode.\n",
    "\n",
    "In every step, we re`fit` the model with input data `X_train` which contains filtered rows (rows with a certain `user_id`) and filtered columns (columns for `electrode` which the accuracy is being caculated for) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_mode_users(model: SVC, X_train_org: DataFrame, X_test_org: DataFrame, y_train_org: DataFrame, y_test_org: DataFrame, channels_good: list, num_users: int) -> List:\n",
    "    \"\"\"\n",
    "    Calculate single accuracy for each channel (Acc_i) for each user.\n",
    "    \"\"\"\n",
    "    user_channel_acc: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        for ch in channels_good:\n",
    "            X_train = X_train_org.loc[X_train_org[\"user_id\"] == user_id, X_train_org.columns.str.contains(ch)]\n",
    "            X_test = X_test_org.loc[X_test_org[\"user_id\"] == user_id, X_test_org.columns.str.contains(ch)]\n",
    "\n",
    "            y_train = y_train_org[y_train_org[\"user_id\"] == user_id][\"label\"]\n",
    "            y_test = y_test_org[y_test_org[\"user_id\"] == user_id][\"label\"]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            if user_id not in user_channel_acc:\n",
    "                user_channel_acc[user_id] = {}\n",
    "            user_channel_acc[user_id][ch] = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate weight for each user for each channel (V_i).\n",
    "\n",
    "    users_channel_weights = [\n",
    "        { #user1\n",
    "            \"FP1\": 0.9,\n",
    "            \"FP2\": 0.3\n",
    "            ...\n",
    "        },\n",
    "        { #user2\n",
    "            \"FP1\": 0.5,\n",
    "            \"FP2\": 0.6\n",
    "            ...\n",
    "        }\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    users_channel_weights = []\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        channel_weights = {}\n",
    "\n",
    "        for channel_a_name in channels_good:\n",
    "            sum_elements = []\n",
    "\n",
    "            for channel_b_name in channels_good:\n",
    "                \"\"\"\n",
    "                Calculate Acc(i,j) and add it to sum expression\n",
    "                \"\"\"\n",
    "                if channel_b_name == channel_a_name:\n",
    "                    break\n",
    "\n",
    "                X_train = X_train_org.loc[X_train_org[\"user_id\"] == user_id, X_train_org.columns.str.contains(\"|\".join([channel_a_name, channel_b_name]))]\n",
    "\n",
    "                X_test = X_test_org.loc[X_test_org[\"user_id\"] == user_id, X_test_org.columns.str.contains(\"|\".join([channel_a_name, channel_b_name]))]\n",
    "\n",
    "                y_train = y_train_org[y_train_org[\"user_id\"] == user_id][\"label\"]\n",
    "                y_test = y_test_org[y_test_org[\"user_id\"] == user_id][\"label\"]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                y_test_pred = model.predict(X_test)\n",
    "\n",
    "                acc_ij = accuracy_score(y_test, y_test_pred)\n",
    "                sum_elements.append(acc_ij + user_channel_acc[user_id][channel_a_name] - user_channel_acc[user_id][channel_b_name])\n",
    "\n",
    "            sum_expression = sum(sum_elements)\n",
    "            acc_i = user_channel_acc[user_id][channel_a_name]\n",
    "            weight = (acc_i + sum_expression) / len(channels_good)\n",
    "            channel_weights[channel_a_name] = weight\n",
    "        users_channel_weights.append(channel_weights)\n",
    "\n",
    "    weights = []\n",
    "    for channel_i in range(len(channels_good)):\n",
    "        channel_name = channels_good[channel_i]\n",
    "        avg_weight = sum(map(lambda x: x[channel_name], users_channel_weights)) / len(users_channel_weights)\n",
    "        weights.append([channel_name, avg_weight])\n",
    "\n",
    "    return sorted(weights, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 - caculate significant electrodes for the whole dataset\n",
    "\n",
    "In this method weights for each electrode is caculated with the whole dataset. Instead of filtering users they are all taken into account when caculating the weight for a specific electrode. These **weights will generally be lower** than weights in the **Method 1**. Significant electrodes are individual for each participant and a single electrode usually doesn't perform well on all participants.\n",
    "\n",
    "For example: electrode A might perform well for users (3,4) but not well for the rest of the users (1,2,5,...,12). Because electrode A has no significance in predicting state for users (1,2,5,...,12) accuracy will be low for them but high for other two (3,4). This results in validation disbalance because validation is done on all participants, even though electrode performs well for only 2 participants (3,4), resulting in accuracy that's generally low compared to **Method 1** accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_mode_all(model: SVC, X_train_org: DataFrame, X_test_org: DataFrame, y_train_org: DataFrame, y_test_org: DataFrame, channels_good: list) -> List:\n",
    "    \"\"\"\n",
    "    Calculate single accuracy for each channel (Acc_i) on the whole dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    channel_acc: Dict[str, float] = {}\n",
    "\n",
    "    for ch in tqdm(channels_good):\n",
    "        X_train = X_train_org.loc[:, X_train_org.columns.str.contains(ch)]\n",
    "        X_test = X_test_org.loc[:, X_test_org.columns.str.contains(ch)]\n",
    "\n",
    "        y_train = y_train_org[\"label\"]\n",
    "        y_test = y_test_org[\"label\"]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        channel_acc[ch] = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate weight for the whole dataset for each channel (V_i).\n",
    "    \"\"\"\n",
    "\n",
    "    channel_weights = {}\n",
    "    for channel_a_name in tqdm(channels_good):\n",
    "        sum_elements = []\n",
    "        for channel_b_name in channels_good:\n",
    "            \"\"\"\n",
    "            Calculate Acc(i,j) and add it to sum expression\n",
    "            \"\"\"\n",
    "            if channel_b_name == channel_a_name:\n",
    "                break\n",
    "\n",
    "            X_train = X_train_org.loc[:, X_train_org.columns.str.contains(\"|\".join([channel_a_name, channel_b_name]))]\n",
    "\n",
    "            X_test = X_test_org.loc[:, X_test_org.columns.str.contains(\"|\".join([channel_a_name, channel_b_name]))]\n",
    "\n",
    "            y_train = y_train_org[\"label\"]\n",
    "            y_test = y_test_org[\"label\"]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            acc_ij = accuracy_score(y_test, y_test_pred)\n",
    "            sum_elements.append(acc_ij + channel_acc[channel_a_name] - channel_acc[channel_b_name])\n",
    "\n",
    "        sum_expression = sum(sum_elements)\n",
    "        acc_i = channel_acc[channel_a_name]\n",
    "        weight = (acc_i + sum_expression) / len(channels_good)\n",
    "        channel_weights[channel_a_name] = weight\n",
    "\n",
    "    return sorted(channel_weights.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significant electrodes results (method 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = Path(PATH_DATAFRAME,\"complete-normalized-with_user_id-2021-12-08-16-10-19-.pkl\")\n",
    "svm_file = Path(PATH_MODEL, \"svc-0.9772--2021-12-09-19-28-39-c=100__gamma=0.03125.model\")\n",
    "\n",
    "mode = \"users\"\n",
    "stdout_to_file(Path(PATH_REPORT, \"-\".join([\"significant-electrodes\", mode, get_timestamp()]) + \".txt\"))\n",
    "model: SVC = load_model(svm_file).best_estimator_\n",
    "\n",
    "df = read_pickle(df_file)\n",
    "X = df.loc[:, ~df.columns.isin([\"label\"])]\n",
    "y = df.loc[:, df.columns.isin([\"label\", \"user_id\"])]\n",
    "\n",
    "X_train_org, X_test_org, y_train_org, y_test_org = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "result = []\n",
    "if mode == \"users\":\n",
    "    result = caculate_mode_users(model, X_train_org, X_test_org, y_train_org, y_test_org, channels_good, 1)\n",
    "else:\n",
    "    result = caculate_mode_all(model, X_train_org, X_test_org, y_train_org, y_test_org, channels_good)\n",
    "\n",
    "for line in result:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - method 1 (users)\n",
      "T6 1.0734463276836157\n",
      "PZ 1.0047457627118643\n",
      "OZ 0.9758192090395482\n",
      "P4 0.9508474576271185\n",
      "P3 0.9317514124293781\n",
      "TP7 0.727231638418079\n",
      "CP4 0.7259887005649716\n",
      "CP3 0.7074576271186442\n",
      "O2 0.6589830508474576\n",
      "C4 0.6567231638418078\n",
      "C3 0.5865536723163841\n",
      "T4 0.5846327683615821\n",
      "CPZ 0.5729943502824858\n",
      "CZ 0.5348022598870056\n",
      "T5 0.49853107344632774\n",
      "T3 0.487909604519774\n",
      "O1 0.4325423728813559\n",
      "FC4 0.38655367231638416\n",
      "FC3 0.34203389830508474\n",
      "TP8 0.3403389830508475\n",
      "F8 0.23050847457627116\n",
      "FT8 0.1849717514124294\n",
      "F4 0.1847457627118644\n",
      "FZ 0.16180790960451977\n",
      "FCZ 0.15389830508474578\n",
      "FT7 0.1275706214689266\n",
      "F7 0.10531073446327684\n",
      "F3 0.06180790960451978\n",
      "FP1 0.03186440677966102\n",
      "FP2 0.031073446327683614\n"
     ]
    }
   ],
   "source": [
    "print_report(Path(PATH_REPORT, \"significant-electrodes-users-2021-12-10-17-02-12.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - method 2 (all)\n",
      "OZ 0.6401944444444445\n",
      "PZ 0.6289537037037037\n",
      "P3 0.6274166666666667\n",
      "P4 0.6094722222222223\n",
      "O2 0.5799074074074073\n",
      "T6 0.5309166666666667\n",
      "O1 0.4751111111111111\n",
      "T5 0.45475925925925925\n",
      "CP4 0.4461851851851852\n",
      "CP3 0.43670370370370376\n",
      "C4 0.4175277777777778\n",
      "CPZ 0.4126759259259259\n",
      "TP8 0.3790925925925926\n",
      "T4 0.360425925925926\n",
      "TP7 0.34452777777777777\n",
      "CZ 0.3377037037037037\n",
      "C3 0.33743518518518517\n",
      "T3 0.27457407407407414\n",
      "FT8 0.2559259259259259\n",
      "FC4 0.24810185185185182\n",
      "FC3 0.18650925925925924\n",
      "FCZ 0.16980555555555554\n",
      "FT7 0.15473148148148147\n",
      "F8 0.13362962962962963\n",
      "F4 0.11733333333333333\n",
      "FZ 0.09979629629629631\n",
      "F3 0.07228703703703704\n",
      "F7 0.062101851851851846\n",
      "FP2 0.036509259259259255\n",
      "FP1 0.02228703703703704\n"
     ]
    }
   ],
   "source": [
    "print_report(Path(PATH_REPORT, \"significant-electrodes-all-2021-12-08-21-04-07.txt\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0f6e9e017e8a47196d14db3343254a5dc30a011a5fa0aa21ff694d62f7585d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
