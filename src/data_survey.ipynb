{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matej/2-fer/uuzop/eeg-driver-fatigue-detection\n"
     ]
    }
   ],
   "source": [
    "# import and config\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from os import getcwd, listdir, path\n",
    "import os \n",
    "import scipy.io\n",
    "import warnings\n",
    "from typing import Dict, Generic\n",
    "from sklearn import preprocessing\n",
    "from typing import TypeVar\n",
    "from IPython.display import display, HTML\n",
    "import EntropyHub as eh\n",
    "import math\n",
    "import antropy as ant\n",
    "from functools import reduce\n",
    "import numba as nb\n",
    "import time\n",
    "\n",
    "%matplotlib qt\n",
    "%cd /home/matej/2-fer/uuzop/eeg-driver-fatigue-detection/\n",
    "\n",
    "UNZIP_DATA = False\n",
    "PATH_CWD = Path(getcwd()) \n",
    "PATH_DATA = Path(PATH_CWD, \"data\")\n",
    "PATH_DATA_MAT = Path(PATH_DATA, \"mat\")\n",
    "PATH_DATA_CNT = Path(PATH_DATA, \"cnt\")\n",
    "PATH_ZIP_CNT = Path(PATH_DATA, \"5202739.zip\")\n",
    "PATH_ZIP_MAT = Path(PATH_DATA, \"5202751.zip\")\n",
    "\n",
    "FREQ = 1000\n",
    "USER_COUNT = 12\n",
    "EPOCH_SECONDS = 1\n",
    "\n",
    "SAFETY_CUTOFF_SECONDS = 20\n",
    "SIGNAL_FILE_DURATION_SECONDS = 600\n",
    "SIGNAL_REQUESTED_SECONDS = 300\n",
    "\n",
    "FATIGUE_STR = \"fatigue\"\n",
    "NORMAL_STR = \"normal\"\n",
    "\n",
    "ELECTRODE_NAMES=['HEOL', 'HEOR', 'FP1', 'FP2', 'VEOU', 'VEOL', 'F7', 'F3', 'FZ', 'F4', 'F8', 'FT7', 'FC3', 'FCZ', 'FC4', 'FT8', 'T3', 'C3', 'CZ', 'C4', 'T4', 'TP7', 'CP3', 'CPZ', 'CP4', 'TP8', 'A1', 'T5', 'P3', 'PZ', 'P4', 'T6', 'A2', 'O1', 'OZ', 'O2', 'FT9', 'FT10', 'PO1', 'PO2']\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET DUMMIES FOR FASTER PRODUCTION\n",
    "# SIGNAL_REQUESTED_SECONDS = 30\n",
    "# USER_COUNT = 5\n",
    "# ELECTRODE_NAMES = ELECTRODE_NAMES[2:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstractions\n",
    "T = TypeVar('T') #Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNT - unzip and restructure data\n",
    "if  UNZIP_DATA:\n",
    "    with ZipFile(PATH_ZIP_CNT, 'r') as zip_ref:\n",
    "        zip_ref.extractall(PATH_DATA_CNT)\n",
    "    \n",
    "    zips = [file for file in PATH_DATA_CNT.iterdir() if str(file).endswith(\".zip\")]\n",
    "    \n",
    "    for zip_item in zips:\n",
    "        \n",
    "        if not str(zip_item).endswith(\".zip\"):\n",
    "            continue\n",
    "        \n",
    "        zip_ref = ZipFile(zip_item) # create zipfile object\n",
    "        \n",
    "        for cnt_file in zip_ref.namelist()[1:]: # ignore \"9/\" directory\n",
    "        \n",
    "            prefix_number = zip_item.stem # 9\n",
    "            state_name = Path(cnt_file).stem.lower().split(' ')[0] # \"Normal State\" -> \"normal\"\n",
    "            filename = Path(prefix_number + '_' + state_name + \".cnt\")\n",
    "            \n",
    "            with open(Path(PATH_DATA_CNT, filename), \"wb\") as new_file:\n",
    "                new_file.write(zip_ref.read(cnt_file))\n",
    "                \n",
    "    # Delete zips as they were temporary\n",
    "    for zip_item in zips:\n",
    "    \tos.remove(zip_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAT - unzip data\n",
    "if  UNZIP_DATA:\n",
    "    with ZipFile(PATH_ZIP_MAT, 'r') as zip_ref:\n",
    "        zip_ref.extractall(PATH_DATA_MAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_apply_procedture(old_dict: Dict[str, T], procedure) -> Dict[str, T]:\n",
    "    return {k: procedure(v) for k, v in old_dict.items()}\n",
    "    \n",
    "def min_max_dataframe(df: pd.DataFrame):\n",
    "    return pd.DataFrame(min_max_scaler(df))\n",
    "\n",
    "def standard_scale_dataframe(df: pd.DataFrame):\n",
    "    return pd.DataFrame(standard_scaler(df))\n",
    "\n",
    "standard_scaler=preprocessing.StandardScaler().fit_transform\n",
    "standard_scaler_1d= lambda x: standard_scaler(x.reshape(-1, 1)).reshape(1,-1).squeeze()\n",
    "\n",
    "min_max_scaler=preprocessing.MinMaxScaler().fit_transform\n",
    "min_max_scaler_1d= lambda x: min_max_scaler(x.reshape(-1, 1)).reshape(1,-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null and NaN are the same in Pandas :)\n",
    "\n",
    "def isnull_any(df):\n",
    "    return df.isnull().any()\n",
    "\n",
    "def isnull_values_sum(df):\n",
    "    return df.isnull().values.sum() > 0\n",
    "\n",
    "def isnull_sum(df):\n",
    "    return df.isnull().sum() > 0\n",
    "\n",
    "def isnull_values_any(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "def rows_with_null(df):\n",
    "    return df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(x, r):\n",
    "    assert isinstance(\n",
    "        r, tuple), 'When Fx = \"Default\", r must be a two-element tuple.'\n",
    "    y = np.exp(-(x**r[1])/r[0])\n",
    "    return y\n",
    "\n",
    "\n",
    "def FuzzEn(Sig,  m=2, tau=1, r=(.2, 2), Fx='default', Logx=np.exp(1)):\n",
    "    N = Sig.shape[0]\n",
    "    m = m+1\n",
    "    Fun = default\n",
    "    Sx = np.zeros((N, m))\n",
    "    for k in range(m):\n",
    "        Sx[:N-k*tau, k] = Sig[k*tau::]\n",
    "\n",
    "    Ps1 = np.zeros(m)\n",
    "    Ps2 = np.zeros(m-1)\n",
    "    Ps1[0] = .5\n",
    "    for k in range(2, m+1):\n",
    "        N1 = N - k*tau\n",
    "        N2 = N - (k-1)*tau\n",
    "        T2 = Sx[:N2, :k] - \\\n",
    "            np.transpose(np.tile(np.mean(Sx[:N2, :k], axis=1), (k, 1)))\n",
    "        d2 = np.zeros((N2-1, N2-1))\n",
    "\n",
    "        for p in range(N2-1):\n",
    "            Mu2 = np.max(\n",
    "                np.abs(np.tile(T2[p, :], (N2-p-1, 1)) - T2[p+1:, :]), axis=1)\n",
    "            d2[p, p:N2] = Fun(Mu2, r)\n",
    "\n",
    "        d1 = d2[:N1-1, :N1-1]\n",
    "        Ps1[k-1] = np.sum(d1)/(N1*(N1-1))\n",
    "        Ps2[k-2] = np.sum(d2)/(N2*(N2-1))\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Fuzz = (np.log(Ps1[:-1]) - np.log(Ps2))/np.log(Logx)\n",
    "\n",
    "    return Fuzz, Ps1, Ps2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition each BCIT dataset includes 4 additional EOG channels placed vertically above the right eye (veou), vertically below the right eye (veol), horizontally on the outside of the right eye (heor), and horizontally on the outside of the left eye (heol)\n",
    "def get_tmin_tmax(start, duration, end_cutoff):\n",
    "\treturn (start - end_cutoff, start + duration - end_cutoff)\n",
    "\t\n",
    "to_numpy_reshape = lambda x: pd.DataFrame.to_numpy(x).reshape(-1,1)\n",
    "fuzzy_entropy = lambda x : eh.FuzzEn(x,m=2, r=(np.std(x, ddof=0) * 0.2,1))[0][-1]\n",
    "sample_entropy = lambda x: ant.sample_entropy(x)\n",
    "# don't normalize because you have to normalze across all users and not based on 1 user and 1 sample\n",
    "spectral_entropy = lambda x: ant.spectral_entropy(x,sf = FREQ, normalize=False)\n",
    "approximate_entropy = lambda x: ant.app_entropy(x,order=2)\n",
    "\n",
    "\n",
    "\n",
    "def pd_fuzzy_entropy(x: pd.Series, standardize_input=False):\n",
    "\tx = x.to_numpy()\n",
    "\tif standardize_input:\n",
    "\t\tx = standard_scaler_1d(x)\n",
    "\treturn fuzzy_entropy(x)\n",
    "# standardization doesnt affect result!\n",
    "def pd_sample_entropy(x: pd.Series, standardize_input=False):\n",
    "\tx = x.to_numpy()\n",
    "\tif standardize_input:\n",
    "\t\tx = standard_scaler_1d(x)\n",
    "\treturn sample_entropy(x)\n",
    "# standardization doesnt affect result!\n",
    "def pd_spectral_entropy(x: pd.Series, standardize_input=False):\n",
    "\tx = x.to_numpy()\n",
    "\tif standardize_input:\n",
    "\t\tx = standard_scaler_1d(x)\n",
    "\treturn spectral_entropy(x)\n",
    "\n",
    "# standardization doesnt affect result!\n",
    "def pd_approximate_entropy(x: pd.Series, standardize_input=False):\n",
    "\tx = x.to_numpy()\n",
    "\tif standardize_input:\n",
    "\t\tx = min_max_scaler_1d(x)\n",
    "\treturn approximate_entropy(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHOWCASE SIGNAL\n",
    "\n",
    "# filename = str(Path(PATH_DATA_CNT, \"2_fatigue.cnt\"))\n",
    "# eeg = mne.io.read_raw_cnt(filename,verbose=False)\n",
    "# eeg_filtered = eeg.load_data(verbose=False).filter(l_freq=0.15, h_freq=40).notch_filter(50)\n",
    "# signal_seconds_floored =  math.floor(len(eeg_filtered) / FREQ)\n",
    "# tmin = signal_seconds_floored - SIGNAL_REQUESTED_SECONDS - SAFETY_CUTOFF_SECONDS\n",
    "# tmax = signal_seconds_floored - SAFETY_CUTOFF_SECONDS\n",
    "# eeg_filtered = eeg_filtered.crop(tmin=tmin, tmax=tmax)\n",
    "# eeg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 df_pe_en 0.027446269989013672\n",
      "User 0 df_ae_en 0.1805276870727539\n",
      "User 0 df_se_en 0.19603991508483887\n",
      "User 0 df_fe_en 4.626615285873413\n",
      "User 0 df_pe_en 0.06715703010559082\n",
      "User 0 df_ae_en 0.22101902961730957\n",
      "User 0 df_se_en 0.25874900817871094\n",
      "User 0 df_fe_en 5.288679361343384\n",
      "User 1 df_pe_en 0.06428813934326172\n",
      "User 1 df_ae_en 0.25064969062805176\n",
      "User 1 df_se_en 0.37012290954589844\n"
     ]
    }
   ],
   "source": [
    "def get_cnt_filename(i_user: int, state:str):\n",
    "\treturn \"{i_user}_{state}.cnt\".format(i_user=i_user, state=state)\n",
    "\t\n",
    "# {(0,normal), (0,fatigue), (1,normal)...(12,fatigue)} \n",
    "user_state_pairs = [(i_user, state) for i_user in range(0, USER_COUNT) for state in [NORMAL_STR, FATIGUE_STR]]\n",
    "arr_total = []\n",
    "for pair in user_state_pairs:\n",
    "\t\n",
    "\ti_user, state = pair\n",
    "\tfilename = str(Path(PATH_DATA_CNT, get_cnt_filename(i_user + 1,state)))\n",
    "\t\n",
    "\t# LOAD, FILTER, CROP AND EPOCH SIGNAL\n",
    "\teeg = mne.io.read_raw_cnt(filename, eog=['HEOL', \"HEOR\", \"VEOU\", \"VEOL\"],verbose=False)\n",
    "\teeg_filtered = eeg.load_data(verbose=False).notch_filter(50).filter(l_freq=0.15, h_freq=40)\n",
    "\tsignal_seconds_floored =  math.floor(len(eeg_filtered) / FREQ)\n",
    "\ttmin = signal_seconds_floored - SIGNAL_REQUESTED_SECONDS - SAFETY_CUTOFF_SECONDS\n",
    "\ttmax = signal_seconds_floored - SAFETY_CUTOFF_SECONDS\n",
    "\teeg_filtered = eeg_filtered.crop(tmin=tmin, tmax=tmax)\t\n",
    "\tepochs = mne.make_fixed_length_epochs(eeg, duration=EPOCH_SECONDS, preload=False, verbose=False)\n",
    "\n",
    "\t# CREATE DF\n",
    "\tdf: pd.DataFrame = epochs.to_data_frame(scalings=dict(eeg=1, mag=1, grad=1))\n",
    "\tdf['condition'] = df['condition'].astype(int)\n",
    "\tdf.drop('time',axis=1, inplace=True)\n",
    "\n",
    "\tarr_one_user_samples=[]\n",
    "\tfor i_poch in range(0, SIGNAL_REQUESTED_SECONDS):\n",
    "\n",
    "\t\t# take epooch rows, divide electordes and info\n",
    "\t\tdf_epoch = df.loc[df[\"epoch\"]==i_poch]\n",
    "\t\tdf_info: pd.DataFrame = df_epoch.iloc[0, ~df_epoch.columns.isin(ELECTRODE_NAMES)]\n",
    "\t\tdf_electrodes: pd.DataFrame = df_epoch[ELECTRODE_NAMES]\n",
    "\t\tstart = time.time()\n",
    "\t\tdf_pe_en = df_electrodes.apply(func=lambda x: pd_spectral_entropy(x,standardize_input=True), axis=0)\n",
    "\t\tprint(\"User\", i_user, \"df_pe_en\", time.time() - start)\n",
    "\t\tstart = time.time()\n",
    "\t\tdf_ae_en = df_electrodes.apply(func=lambda x: pd_approximate_entropy(x,standardize_input=True), axis=0)\n",
    "\t\tprint(\"User\", i_user, \"df_ae_en\", time.time() - start)\n",
    "\t\tstart = time.time()\n",
    "\t\tdf_se_en = df_electrodes.apply(func=lambda x: pd_sample_entropy(x,standardize_input=True), axis=0)\n",
    "\t\tprint(\"User\", i_user, \"df_se_en\", time.time() - start)\n",
    "\t\tstart = time.time()\n",
    "\t\tdf_fe_en = df_electrodes.apply(func=lambda x: pd_fuzzy_entropy(x,standardize_input=True), axis=0)\n",
    "\t\tprint(\"User\", i_user, \"df_fe_en\", time.time() - start)\n",
    "\t\tarr_one_user_samples.append([*df_info, *df_pe_en, *df_ae_en, *df_se_en, *df_fe_en])\n",
    "\t\tbreak\n",
    "\tarr_total.append(arr_one_user_samples)\n",
    "\n",
    "\n",
    "# test = to_numpy_reshape(epochs_df.loc[epochs_df[\"epoch\"]==1,\"F7\"].to_numpy().reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ant gives correct results !\n",
    "# nk.entropy_fuzzy over eh.FuzzEn\n",
    "# eh.FuzzEn's r are parameters of fuzzy function and not tolerence levels?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe19c08dd3cf647ff4425e243f58ff50b00b8fe922eacf7722406d8fcabc1f65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
